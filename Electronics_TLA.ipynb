{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import graphlab\n",
    "import pandas\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import string\n",
    "#xml_data = open('/home/omar/data/train-data/kitchen/positive.review').read()\n",
    "\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            record[subchild.tag] = subchild.text\n",
    "            all_records.append(record)\n",
    "    return pd.DataFrame(all_records)\n",
    "from pathlib2 import Path\n",
    "def extract(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    datacheck=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    review = False\n",
    "    #contents = Path(xml_data).read_text()\n",
    "    for l in File:  #File\n",
    "        l = l.replace('\\n', '')\n",
    "        #l = l.replace(\"'\\u001a'\",'')\n",
    "        \n",
    "    \n",
    "        #l = l.replace('\\t', '')\n",
    "        #l = l.replace('\"', '')\n",
    "        if review and \"</review_text>\" not in l:\n",
    "            revtext+=l\n",
    "            #data.append(l)\n",
    "            \n",
    "        \n",
    "        if \"<review_text>\" in l:\n",
    "            review = True\n",
    "        if \"</review_text>\" in l:\n",
    "            data.append(revtext)\n",
    "            revtext=\"\"\n",
    "            review = False\n",
    "        \n",
    "    return data\n",
    "        \n",
    "\n",
    "\n",
    "def extract_summarized(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    for l in File:\n",
    "        l = l.replace('\\n', '')\n",
    "        \n",
    "        \n",
    "        ##if '<' not in l and '>' not in l and not l.isdigit():\n",
    "            ##data.append(l)\n",
    "        ##if review:\n",
    "            ##data.append(l)\n",
    "            ##review = False\n",
    "        if inreview:\n",
    "            data.append(l)\n",
    "            inreview=False\n",
    "        #\"xxxxABCDyyyy\".find(\"ABCD\") != -1:\n",
    "        if l.find(\"<review_text>\")!=-1:\n",
    "            inreview=True\n",
    "            \n",
    "        #if \"</review_text>\" in l:\n",
    "            #data.append(revtext)\n",
    "            #revtext=\"\"\n",
    "            #inreview=False\n",
    "    return data\n",
    "\n",
    "def Advanced_Extract(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    for l in File:\n",
    "        revtext+=l\n",
    "    subtext=\"\"\n",
    "    for word in revtext.split(\" \"):\n",
    "        if inreview:\n",
    "            subtext+=word + \" \"\n",
    "        if \"<review_text> \" in word:\n",
    "            inreview=True\n",
    "        if \"</review_text> \" in word:\n",
    "            inreview=False\n",
    "            data.append(subtext)\n",
    "            subtext=\"\"\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "domains = defaultdict(str)\n",
    "domainnames = ['booksgl','electronicsgl','dvdgl','apparelgl','automotivegl','babygl','beautygl','cameraphotogl','computervideo_gamesgl',\n",
    "           'gourmet_foodgl','grocerygl','healthpersonal_caregl','jewelrywatchesgl']\n",
    "\n",
    "import graphlab as gl\n",
    "\n",
    "kitchengl = gl.SFrame('kitechen_reviews.csv')\n",
    "booksgl = gl.SFrame('books_reviews.csv')\n",
    "domains['booksgl'] = booksgl\n",
    "electronicsgl = gl.SFrame('electronics_reviews.csv')\n",
    "domains['electronicsgl'] = electronicsgl\n",
    "dvdgl = gl.SFrame('dvd_reviews.csv')\n",
    "domains['dvdgl'] = dvdgl\n",
    "\n",
    "apparelgl = gl.SFrame('apparel_reviews.csv')\n",
    "domains['apparelgl'] = apparelgl\n",
    "automotivegl = gl.SFrame('automotive_reviews.csv')\n",
    "domains['automotivegl'] = automotivegl\n",
    "babygl = gl.SFrame('baby_reviews.csv')\n",
    "domains['babygl'] = babygl\n",
    "\n",
    "beautygl = gl.SFrame('beauty_reviews.csv')\n",
    "domains['beautygl'] = beautygl\n",
    "cameraphotogl = gl.SFrame('cameraphoto_reviews.csv')\n",
    "domains['cameraphotogl'] = cameraphotogl\n",
    "computervideo_gamesgl = gl.SFrame('computervideo_games_reviews.csv')\n",
    "domains['computervideo_gamesgl'] = computervideo_gamesgl\n",
    "\n",
    "gourmet_foodgl = gl.SFrame('gourmet_food_reviews.csv')\n",
    "domains['gourmet_foodgl'] = gourmet_foodgl\n",
    "grocerygl = gl.SFrame('grocery_reviews.csv')\n",
    "domains['grocerygl'] = grocerygl\n",
    "healthpersonal_caregl = gl.SFrame('healthpersonal_care_reviews.csv')\n",
    "domains['healthpersonal_caregl'] = healthpersonal_caregl\n",
    "\n",
    "jewelrywatchesgl = gl.SFrame('jewelrywatches_reviews.csv')\n",
    "domains['jewelrywatchesgl'] = jewelrywatchesgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538274025.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.120924 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.120924 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 23009 lines in 0.116933 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 23009 lines in 0.116933 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "electronicsgl = gl.SFrame('electronics_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicsglpos = electronicsgl[electronicsgl['label']==1]\n",
    "electronicsglneg = electronicsgl[electronicsgl['label']==0]\n",
    "\n",
    "electronicsglpos500 = electronicsglpos[:500]\n",
    "electronicsglneg500 = electronicsglneg[:500]\n",
    "del electronicsglneg500['label']\n",
    "del electronicsglpos500['label']\n",
    "electronicsglpos500.save('electronicsglpos500.csv')\n",
    "electronicsglneg500.save('electronicsglneg500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "electronicsglpos500pd = pd.read_csv('electronicsglpos500.csv')\n",
    "electronicsglneg500pd = pd.read_csv('electronicsglneg500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electronicsglpos500pd.to_csv('electronicsglpos500pd.txt',index=False)\n",
    "electronicsglneg500pd.to_csv('electronicsglneg500pd.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apparelgl['word_count'] = gl.text_analytics.count_words(apparelgl['review'])\n",
    "automotivegl['word_count'] = gl.text_analytics.count_words(automotivegl['review'])\n",
    "babygl['word_count'] = gl.text_analytics.count_words(babygl['review'])\n",
    "beautygl['word_count'] = gl.text_analytics.count_words(beautygl['review'])\n",
    "cameraphotogl['word_count'] = gl.text_analytics.count_words(cameraphotogl['review'])\n",
    "computervideo_gamesgl['word_count'] = gl.text_analytics.count_words(computervideo_gamesgl['review'])\n",
    "gourmet_foodgl['word_count'] = gl.text_analytics.count_words(gourmet_foodgl['review'])\n",
    "grocerygl['word_count'] = gl.text_analytics.count_words(grocerygl['review'])\n",
    "\n",
    "healthpersonal_caregl['word_count'] = gl.text_analytics.count_words(healthpersonal_caregl['review'])\n",
    "jewelrywatchesgl['word_count'] = gl.text_analytics.count_words(jewelrywatchesgl['review'])\n",
    "\n",
    "import graphlab\n",
    "apparelgl['3-grams'] = graphlab.text_analytics.count_ngrams(apparelgl['review'], 3)\n",
    "apparelgl['2-grams'] = graphlab.text_analytics.count_ngrams(apparelgl['review'], 2)\n",
    "apparelgl['1-grams'] = graphlab.text_analytics.count_ngrams(apparelgl['review'], 1)\n",
    "\n",
    "automotivegl['3-grams'] = graphlab.text_analytics.count_ngrams(automotivegl['review'], 3)\n",
    "automotivegl['2-grams'] = graphlab.text_analytics.count_ngrams(automotivegl['review'], 2)\n",
    "automotivegl['1-grams'] = graphlab.text_analytics.count_ngrams(automotivegl['review'], 1)\n",
    "\n",
    "babygl['3-grams'] = graphlab.text_analytics.count_ngrams(babygl['review'], 3)\n",
    "babygl['2-grams'] = graphlab.text_analytics.count_ngrams(babygl['review'], 2)\n",
    "babygl['1-grams'] = graphlab.text_analytics.count_ngrams(babygl['review'], 1)\n",
    "\n",
    "beautygl['3-grams'] = graphlab.text_analytics.count_ngrams(beautygl['review'], 3)\n",
    "beautygl['2-grams'] = graphlab.text_analytics.count_ngrams(beautygl['review'], 2)\n",
    "beautygl['1-grams'] = graphlab.text_analytics.count_ngrams(beautygl['review'], 1)\n",
    "\n",
    "cameraphotogl['3-grams'] = graphlab.text_analytics.count_ngrams(cameraphotogl['review'], 3)\n",
    "cameraphotogl['2-grams'] = graphlab.text_analytics.count_ngrams(cameraphotogl['review'], 2)\n",
    "cameraphotogl['1-grams'] = graphlab.text_analytics.count_ngrams(cameraphotogl['review'], 1)\n",
    "\n",
    "computervideo_gamesgl['3-grams'] = graphlab.text_analytics.count_ngrams(computervideo_gamesgl['review'], 3)\n",
    "computervideo_gamesgl['2-grams'] = graphlab.text_analytics.count_ngrams(computervideo_gamesgl['review'], 2)\n",
    "computervideo_gamesgl['1-grams'] = graphlab.text_analytics.count_ngrams(computervideo_gamesgl['review'], 1)\n",
    "\n",
    "gourmet_foodgl['3-grams'] = graphlab.text_analytics.count_ngrams(gourmet_foodgl['review'], 3)\n",
    "gourmet_foodgl['2-grams'] = graphlab.text_analytics.count_ngrams(gourmet_foodgl['review'], 2)\n",
    "gourmet_foodgl['1-grams'] = graphlab.text_analytics.count_ngrams(gourmet_foodgl['review'], 1)\n",
    "\n",
    "grocerygl['3-grams'] = graphlab.text_analytics.count_ngrams(grocerygl['review'], 3)\n",
    "grocerygl['2-grams'] = graphlab.text_analytics.count_ngrams(grocerygl['review'], 2)\n",
    "grocerygl['1-grams'] = graphlab.text_analytics.count_ngrams(grocerygl['review'], 1)\n",
    "\n",
    "healthpersonal_caregl['3-grams'] = graphlab.text_analytics.count_ngrams(healthpersonal_caregl['review'], 3)\n",
    "healthpersonal_caregl['2-grams'] = graphlab.text_analytics.count_ngrams(healthpersonal_caregl['review'], 2)\n",
    "healthpersonal_caregl['1-grams'] = graphlab.text_analytics.count_ngrams(healthpersonal_caregl['review'], 1)\n",
    "\n",
    "jewelrywatchesgl['3-grams'] = graphlab.text_analytics.count_ngrams(jewelrywatchesgl['review'], 3)\n",
    "jewelrywatchesgl['2-grams'] = graphlab.text_analytics.count_ngrams(jewelrywatchesgl['review'], 2)\n",
    "jewelrywatchesgl['1-grams'] = graphlab.text_analytics.count_ngrams(jewelrywatchesgl['review'], 1)\n",
    "\n",
    "\n",
    "apparelgl['tfidf'] = gl.text_analytics.tf_idf(apparelgl['word_count'])\n",
    "\n",
    "automotivegl['tfidf'] = gl.text_analytics.tf_idf(automotivegl['word_count'])\n",
    "babygl['tfidf'] = gl.text_analytics.tf_idf(babygl['word_count'])\n",
    "beautygl['tfidf'] = gl.text_analytics.tf_idf(beautygl['word_count'])\n",
    "\n",
    "cameraphotogl['tfidf'] = gl.text_analytics.tf_idf(cameraphotogl['word_count'])\n",
    "\n",
    "computervideo_gamesgl['tfidf'] = gl.text_analytics.tf_idf(computervideo_gamesgl['word_count'])\n",
    "gourmet_foodgl['tfidf'] = gl.text_analytics.tf_idf(gourmet_foodgl['word_count'])\n",
    "grocerygl['tfidf'] = gl.text_analytics.tf_idf(grocerygl['word_count'])\n",
    "\n",
    "healthpersonal_caregl['tfidf'] = gl.text_analytics.tf_idf(healthpersonal_caregl['word_count'])\n",
    "jewelrywatchesgl['tfidf'] = gl.text_analytics.tf_idf(jewelrywatchesgl['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicsgl['word_count'] = gl.text_analytics.count_words(electronicsgl['review'])\n",
    "kitchengl['word_count'] = gl.text_analytics.count_words(kitchengl['review'])\n",
    "booksgl['word_count'] = gl.text_analytics.count_words(booksgl['review'])\n",
    "dvdgl['word_count'] = gl.text_analytics.count_words(dvdgl['review'])\n",
    "electronicsgl['3-grams'] = graphlab.text_analytics.count_ngrams(electronicsgl['review'], 3)\n",
    "electronicsgl['2-grams'] = graphlab.text_analytics.count_ngrams(electronicsgl['review'], 2)\n",
    "electronicsgl['1-grams'] = graphlab.text_analytics.count_ngrams(electronicsgl['review'], 1)\n",
    "\n",
    "kitchengl['3-grams'] = graphlab.text_analytics.count_ngrams(kitchengl['review'], 3)\n",
    "kitchengl['2-grams'] = graphlab.text_analytics.count_ngrams(kitchengl['review'], 2)\n",
    "kitchengl['1-grams'] = graphlab.text_analytics.count_ngrams(kitchengl['review'], 1)\n",
    "\n",
    "booksgl['3-grams'] = graphlab.text_analytics.count_ngrams(booksgl['review'], 3)\n",
    "booksgl['2-grams'] = graphlab.text_analytics.count_ngrams(booksgl['review'], 2)\n",
    "booksgl['1-grams'] = graphlab.text_analytics.count_ngrams(booksgl['review'], 1)\n",
    "\n",
    "dvdgl['3-grams'] = graphlab.text_analytics.count_ngrams(dvdgl['review'], 3)\n",
    "dvdgl['2-grams'] = graphlab.text_analytics.count_ngrams(dvdgl['review'], 2)\n",
    "dvdgl['1-grams'] = graphlab.text_analytics.count_ngrams(dvdgl['review'], 1)\n",
    "\n",
    "electronicsgl['tfidf'] = gl.text_analytics.tf_idf(electronicsgl['word_count'])\n",
    "\n",
    "kitchengl['tfidf'] = gl.text_analytics.tf_idf(kitchengl['review'])\n",
    "booksgl['tfidf'] = gl.text_analytics.tf_idf(booksgl['review'])\n",
    "dvdgl['tfidf'] = gl.text_analytics.tf_idf(dvdgl['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1537833965.log.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.064947 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.064947 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 19856 lines in 0.08495 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 19856 lines in 0.08495 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\books_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\books_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.357795 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.357795 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 54835 lines. Lines per second: 117236</pre>"
      ],
      "text/plain": [
       "Read 54835 lines. Lines per second: 117236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"A most circumspect, articulate and historically (non-revisionist) accurate evaluaton of our political, environmental and practical lives in the US of A today.Important and enlightening info in an age of increasing civil rights suppression and heightened f...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"A most circumspect, articulate and historically (non-revisionist) accurate evaluaton of our political, environmental and practical lives in the US of A today.Important and enlightening info in an age of increasing civil rights suppression and heightened f...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I loved this story all the way through!  I \"\"read\"\" while I drive, so I did the audio CD, (unabridged), and it was delightful!  The storline was so fun and quirky and did have me laughing at so many parts... I do like Maz!  This is a woman we all know!  S...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I loved this story all the way through!  I \"\"read\"\" while I drive, so I did the audio CD, (unabridged), and it was delightful!  The storline was so fun and quirky and did have me laughing at so many parts... I do like Maz!  This is a woman we all know!  S...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I thoroughly enjoyed this book and had a hard time putting it down.  All of the characters were very enjoyable and Natalie aka: Cressida was a gas!  Such a girlfriend!  She was believable, at least in my world!, and I could totally see myself falling into...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I thoroughly enjoyed this book and had a hard time putting it down.  All of the characters were very enjoyable and Natalie aka: Cressida was a gas!  Such a girlfriend!  She was believable, at least in my world!, and I could totally see myself falling into...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>5 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "5 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\books_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\books_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 975189 lines in 5.54883 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 975189 lines in 5.54883 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.101941 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.101941 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 23009 lines in 0.117934 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 23009 lines in 0.117934 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.416742 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.416742 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 52466 lines. Lines per second: 105414</pre>"
      ],
      "text/plain": [
       "Read 52466 lines. Lines per second: 105414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 124438 lines in 0.825526 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 124438 lines in 0.825526 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.041976 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.041976 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 9252 lines in 0.040987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 9252 lines in 0.040987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.021998 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.021998 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 736 lines in 0.01999 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 736 lines in 0.01999 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.035978 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.035978 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 4256 lines in 0.035997 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 4256 lines in 0.035997 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.028983 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.028983 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2884 lines in 0.027985 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2884 lines in 0.027985 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.053968 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.053968 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 7408 lines in 0.05097 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 7408 lines in 0.05097 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1575 lines in 0.021987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1575 lines in 0.021987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2632 lines in 0.023986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2632 lines in 0.023986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.041975 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.041975 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 7225 lines in 0.040976 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 7225 lines in 0.040976 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1981 lines in 0.023005 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1981 lines in 0.023005 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "##original\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "domains = defaultdict(str)\n",
    "domainnames = ['booksgl','electronicsgl','dvdgl','apparelgl','automotivegl','babygl','beautygl','cameraphotogl','computervideo_gamesgl',\n",
    "           'gourmet_foodgl','grocerygl','healthpersonal_caregl','jewelrywatchesgl']\n",
    "\n",
    "import graphlab as gl\n",
    "\n",
    "kitchengl = gl.SFrame('kitechen_reviews.csv')\n",
    "booksgl = gl.SFrame('books_reviews.csv')\n",
    "domains['booksgl'] = booksgl\n",
    "electronicsgl = gl.SFrame('electronics_reviews.csv')\n",
    "domains['electronicsgl'] = electronicsgl\n",
    "dvdgl = gl.SFrame('dvd_reviews.csv')\n",
    "domains['dvdgl'] = dvdgl\n",
    "\n",
    "apparelgl = gl.SFrame('apparel_reviews.csv')\n",
    "domains['apparelgl'] = apparelgl\n",
    "automotivegl = gl.SFrame('automotive_reviews.csv')\n",
    "domains['automotivegl'] = automotivegl\n",
    "babygl = gl.SFrame('baby_reviewsUpdated.csv')\n",
    "domains['babygl'] = babygl\n",
    "\n",
    "beautygl = gl.SFrame('beauty_reviews.csv')\n",
    "domains['beautygl'] = beautygl\n",
    "cameraphotogl = gl.SFrame('cameraphoto_reviews.csv')\n",
    "domains['cameraphotogl'] = cameraphotogl\n",
    "#computervideo_gamesgl = gl.SFrame('computervideo_games_reviews.csv')\n",
    "computervideo_gamesdf = pd.read_csv('computervideo_games_reviews.csv')\n",
    "computervideo_gamesgl = gl.SFrame(data=computervideo_gamesdf)\n",
    "domains['computervideo_gamesgl'] = computervideo_gamesgl\n",
    "\n",
    "gourmet_foodgl = gl.SFrame('gourmet_food_reviews.csv')\n",
    "domains['gourmet_foodgl'] = gourmet_foodgl\n",
    "grocerygl = gl.SFrame('grocery_reviews.csv')\n",
    "domains['grocerygl'] = grocerygl\n",
    "healthpersonal_caregl = gl.SFrame('healthpersonal_care_reviews.csv')\n",
    "domains['healthpersonal_caregl'] = healthpersonal_caregl\n",
    "\n",
    "jewelrywatchesgl = gl.SFrame('jewelrywatches_reviews.csv')\n",
    "domains['jewelrywatchesgl'] = jewelrywatchesgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#electronicsgl\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "def reviewcleaner(text):\n",
    "    #postags = ['JJ', 'JJR', 'JJS','VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','RB', 'RBR', 'RBS']\n",
    "    postags = ['JJ','VB','RB']\n",
    "    #Nountags = ['NN', 'NNP', 'NNS']\n",
    "    Nountags = ['NN']\n",
    "    #text = \"I love books in general\"\n",
    "\n",
    "    #print words\n",
    "    text = preprocess(text)\n",
    "    raw_words = text.split(\" \")\n",
    "    raw_words2 = text.split(\" \")\n",
    "    #nltk.word_tokenize(text)\n",
    "    try:\n",
    "        words = nltk.pos_tag(raw_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    newsentence=[]\n",
    "    for i in range(len(raw_words)):\n",
    "\n",
    "        #print raw_words[i]\n",
    "        #print words[i][1]\n",
    "        #print words\n",
    "        #print raw_words\n",
    "        ##if len(raw_words) != len(words):\n",
    "            ##print words\n",
    "            ##print raw_words\n",
    "            ##break\n",
    "        if words[i][1] in postags:\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.80 or hsentiments0.neg_score > 0.80:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "            ##newsentence.append(raw_words[i])\n",
    "        elif words[i][1] in Nountags:\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.80 or hsentiments0.neg_score > 0.80:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "    return  (str(\" \".join(newsentence)))\n",
    "\n",
    "def word_counter(textfilepath):\n",
    "    \n",
    "    \n",
    "    #'your_file.txt'\n",
    "    with open(textfilepath) as f:\n",
    "        passage = f.readlines()\n",
    "\n",
    "    words = re.findall(r'\\w+', str(passage))\n",
    "\n",
    "    cap_words = [word.upper() for word in words]\n",
    "\n",
    "    word_counts = Counter(cap_words)\n",
    "    return word_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received kingston 256mb sd card advertised unit came mail exactly 2 days iordered worked perfectly satisfied\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    #sentence = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    ##sentence = \" \".join(filtered_words)\n",
    "    #filtered_words = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    #filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    ##return filtered_words\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "\n",
    "#sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "sentence = \"I received my Kingston 256MB SD card just as advertised.The unit came in the mail exactly 2 days after Iordered. Worked perfectly and I'm very satisfied\"\n",
    "#sentence = \"like many\"\n",
    "print preprocess(sentence)\n",
    "text = preprocess(sentence)\n",
    "raw_words = text.split(\" \")\n",
    "words = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print len(raw_words)\n",
    "print len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicsgl_unlabeled = electronicsgl[electronicsgl['label']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicsgl_unlabeled['clean_review'] = electronicsgl_unlabeled['review'].apply(lambda x: reviewcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del electronicsgl_unlabeled['label']\n",
    "del electronicsgl_unlabeled['review']\n",
    "electronicsgl_unlabeled.save('electronicsgl_compact_unlabeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(electronicsgl_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicglcleanreview.csv\")\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicglcleanreview_compact.csv\")\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview_compact.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview_compact.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview_compact.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicsgl_compact_unlabeled.csv\")\n",
    "#\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview_compact_unlabeled.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview_compact_unlabeled.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview_compact_unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "apparelgl_wordcount = word_counter(\"apparelglcleanreview_compact2.csv\")\n",
    "automotivegl_wordcount = word_counter(\"automotiveglcleanreview_compact2.csv\")\n",
    "babygl_wordcount = word_counter(\"babyglcleanreview_compact2.csv\")\n",
    "beautygl_wordcount = word_counter(\"beautyglcleanreview_compact2.csv\")\n",
    "cameraphotogl_wordcount = word_counter(\"cameraphotoglcleanreview_compact2.csv\")\n",
    "computervideo_gamesgl_wordcount = word_counter(\"computervideo_gamesglcleanreview_compact2.csv\")\n",
    "gourmet_foodgl_wordcount = word_counter(\"gourmet_foodglcleanreview_compact2.csv\")\n",
    "grocerygl_wordcount = word_counter(\"groceryglcleanreview_compact2.csv\")\n",
    "healthpersonal_caregl_wordcount = word_counter(\"healthpersonal_careglcleanreview_compact2.csv\")\n",
    "jewelrywatchesgl_wordcount = word_counter(\"jewelrywatchesglcleanreview_compact2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1537988401.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    }
   ],
   "source": [
    "#dvd_electronics_distance = gl.distances.cosine(electronics_wordcount,dvdgl_wordcount)\n",
    "import graphlab as gl\n",
    "\n",
    "euclidean_distances_toelectronics={}\n",
    "#kitchen_electronics_distance = gl.distances.euclidean(electronics_wordcount,kitchengl_wordcount)\n",
    "euclidean_distances_toelectronics['book'] = gl.distances.euclidean(electronics_wordcount,booksgl_wordcount)\n",
    "#dvd_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,dvdgl_wordcount)\n",
    "euclidean_distances_toelectronics['dvd'] = gl.distances.euclidean(electronics_wordcount,dvdgl_wordcount)\n",
    "#books_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,booksgl_wordcount)\n",
    "euclidean_distances_toelectronics['kitchen'] = gl.distances.euclidean(electronics_wordcount,kitchengl_wordcount)\n",
    "\n",
    "#apparel_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,apparelgl_wordcount)\n",
    "euclidean_distances_toelectronics['apparel'] = gl.distances.euclidean(electronics_wordcount,apparelgl_wordcount)\n",
    "#automotive_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,automotivegl_wordcount)\n",
    "euclidean_distances_toelectronics['automotive'] = gl.distances.euclidean(electronics_wordcount,automotivegl_wordcount)\n",
    "#baby_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,babygl_wordcount)\n",
    "euclidean_distances_toelectronics['baby'] = gl.distances.euclidean(electronics_wordcount,babygl_wordcount)\n",
    "#beauty_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,beautygl_wordcount)\n",
    "euclidean_distances_toelectronics['beauty'] = gl.distances.euclidean(electronics_wordcount,beautygl_wordcount)\n",
    "#cameraphoto_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,cameraphotogl_wordcount)\n",
    "euclidean_distances_toelectronics['cameraphoto'] = gl.distances.euclidean(electronics_wordcount,cameraphotogl_wordcount)\n",
    "#computervideo_games_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,computervideo_gamesgl_wordcount)\n",
    "euclidean_distances_toelectronics['computervideo'] = gl.distances.euclidean(electronics_wordcount,computervideo_gamesgl_wordcount)\n",
    "#gourmet_food_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,gourmet_foodgl_wordcount)\n",
    "euclidean_distances_toelectronics['gourmet'] = gl.distances.euclidean(electronics_wordcount,gourmet_foodgl_wordcount)\n",
    "#grocery_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,grocerygl_wordcount)\n",
    "euclidean_distances_toelectronics['grocery'] = gl.distances.euclidean(electronics_wordcount,grocerygl_wordcount)\n",
    "#healthpersonal_care_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,healthpersonal_caregl_wordcount)\n",
    "euclidean_distances_toelectronics['healthpersonal'] = gl.distances.euclidean(electronics_wordcount,healthpersonal_caregl_wordcount)\n",
    "#jewelrywatches_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,jewelrywatchesgl_wordcount)\n",
    "euclidean_distances_toelectronics['jewelrywatches'] = gl.distances.euclidean(electronics_wordcount,jewelrywatchesgl_wordcount)\n",
    "\n",
    "electronics_dist_domains = ['book','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicstestgl = graphlab.SFrame('electronicstestgl_predictions2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fscores={}\n",
    "Accuracies={}\n",
    "book_dist_domains = ['book','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    \n",
    "\n",
    "for d in book_dist_domains:\n",
    "    Fscores[d] = graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl[str(d)+'_predictions'])\n",
    "    Accuracies[d] = graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl[str(d)+'_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dvd_electronics_distance = gl.distances.cosine(electronics_wordcount,dvdgl_wordcount)\n",
    "#fscore={}\n",
    "#accuracies={}\n",
    "cosine_distances_toelectronics={}\n",
    "#kitchen_electronics_distance = gl.distances.euclidean(electronics_wordcount,kitchengl_wordcount)\n",
    "cosine_distances_toelectronics['book'] = gl.distances.cosine(electronics_wordcount,booksgl_wordcount)\n",
    "#dvd_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,dvdgl_wordcount)\n",
    "cosine_distances_toelectronics['dvd'] = gl.distances.cosine(electronics_wordcount,dvdgl_wordcount)\n",
    "#books_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,booksgl_wordcount)\n",
    "cosine_distances_toelectronics['kitchen'] = gl.distances.cosine(electronics_wordcount,kitchengl_wordcount)\n",
    "\n",
    "#apparel_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,apparelgl_wordcount)\n",
    "cosine_distances_toelectronics['apparel'] = gl.distances.cosine(electronics_wordcount,apparelgl_wordcount)\n",
    "#automotive_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,automotivegl_wordcount)\n",
    "cosine_distances_toelectronics['automotive'] = gl.distances.cosine(electronics_wordcount,automotivegl_wordcount)\n",
    "#baby_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,babygl_wordcount)\n",
    "cosine_distances_toelectronics['baby'] = gl.distances.cosine(electronics_wordcount,babygl_wordcount)\n",
    "#beauty_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,beautygl_wordcount)\n",
    "cosine_distances_toelectronics['beauty'] = gl.distances.cosine(electronics_wordcount,beautygl_wordcount)\n",
    "#cameraphoto_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,cameraphotogl_wordcount)\n",
    "cosine_distances_toelectronics['cameraphoto'] = gl.distances.cosine(electronics_wordcount,cameraphotogl_wordcount)\n",
    "#computervideo_games_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,computervideo_gamesgl_wordcount)\n",
    "cosine_distances_toelectronics['computervideo'] = gl.distances.cosine(electronics_wordcount,computervideo_gamesgl_wordcount)\n",
    "#gourmet_food_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,gourmet_foodgl_wordcount)\n",
    "cosine_distances_toelectronics['gourmet'] = gl.distances.cosine(electronics_wordcount,gourmet_foodgl_wordcount)\n",
    "#grocery_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,grocerygl_wordcount)\n",
    "cosine_distances_toelectronics['grocery'] = gl.distances.cosine(electronics_wordcount,grocerygl_wordcount)\n",
    "#healthpersonal_care_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,healthpersonal_caregl_wordcount)\n",
    "cosine_distances_toelectronics['healthpersonal'] = gl.distances.cosine(electronics_wordcount,healthpersonal_caregl_wordcount)\n",
    "#jewelrywatches_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,jewelrywatchesgl_wordcount)\n",
    "cosine_distances_toelectronics['jewelrywatches'] = gl.distances.cosine(electronics_wordcount,jewelrywatchesgl_wordcount)\n",
    "\n",
    "electronics_dist_domains = ['book','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "('automotive', 0.5)\n",
      "('gourmet', 0.5025)\n",
      "('jewelrywatches', 0.5025)\n",
      "('grocery', 0.5075)\n",
      "('beauty', 0.5075)\n",
      "('computervideo', 0.51)\n",
      "('book', 0.6425)\n",
      "('dvd', 0.7175)\n",
      "('kitchen', 0.75)\n",
      "('apparel', 0.7625)\n",
      "('baby', 0.77)\n",
      "('healthpersonal', 0.775)\n",
      "('cameraphoto', 0.785)\n",
      "fscores\n",
      "('automotive', 0.0)\n",
      "('book', 0.546031746031746)\n",
      "('gourmet', 0.667779632721202)\n",
      "('jewelrywatches', 0.667779632721202)\n",
      "('beauty', 0.6677908937605396)\n",
      "('grocery', 0.66890756302521)\n",
      "('computervideo', 0.6711409395973155)\n",
      "('dvd', 0.6986666666666667)\n",
      "('kitchen', 0.7354497354497355)\n",
      "('apparel', 0.745308310991957)\n",
      "('healthpersonal', 0.7457627118644068)\n",
      "('cameraphoto', 0.7724867724867724)\n",
      "('baby', 0.7973568281938326)\n",
      "distances\n",
      "('cameraphoto', 87.44712688247682)\n",
      "('baby', 93.33273809334)\n",
      "('healthpersonal', 93.70165420097983)\n",
      "('apparel', 93.79765455489812)\n",
      "('computervideo', 94.55157322858251)\n",
      "('kitchen', 94.66255859631093)\n",
      "('jewelrywatches', 98.4377976185977)\n",
      "('beauty', 99.48366700117161)\n",
      "('automotive', 100.46890066085126)\n",
      "('grocery', 101.41005867269774)\n",
      "('gourmet', 102.33767634649519)\n",
      "('dvd', 165.71662559924397)\n",
      "('book', 214.9116097375849)\n"
     ]
    }
   ],
   "source": [
    "sorted_Fscores = sorted(Fscores.items(), key=lambda x:x[1])\n",
    "sorted_Accuracies = sorted(Accuracies.items(), key=lambda x:x[1])\n",
    "sorted_euclideandistances = sorted(euclidean_distances_toelectronics.items(), key=lambda x:x[1])\n",
    "print \"accuracies\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Accuracies[d]\n",
    "print \"fscores\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Fscores[d]\n",
    "print \"distances\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    #print \"euclidean_distance\"\n",
    "    print sorted_euclideandistances[d]\n",
    "    #print sorted_Fscores[d]\n",
    "    #print sorted_Accuracies[d]\n",
    "    #print sorted_euclideandistances[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728606356968\n",
      "minority_predictions' model Accuracy\n",
      "0.7225\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.541401273885\n",
      "minority_predictions' model Accuracy\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.483985765125\n",
      "minority_predictions' model Accuracy\n",
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.483985765125\n",
      "minority_predictions' model Accuracy\n",
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.817102137767\n",
      "majority_predictions' model Accuracy\n",
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.819587628866\n",
      "majority_predictions' model Accuracy\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.536231884058\n",
      "majority_predictions' model Accuracy\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.81914893617\n",
      "majority_predictions' model Accuracy\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold=0.6\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.824390243902\n",
      "majority_predictions' model Accuracy\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold=0.5\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.728915662651\n",
      "majority_predictions' model Accuracy\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold=0.7\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.6\n",
      "majority_predictions' model Accuracy\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold=0.8\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.303797468354\n",
      "majority_predictions' model Accuracy\n",
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold=0.9\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "('automotive', 0.5)\n",
      "('gourmet', 0.5025)\n",
      "('jewelrywatches', 0.5025)\n",
      "('grocery', 0.5075)\n",
      "('beauty', 0.5075)\n",
      "('computervideo', 0.51)\n",
      "('book', 0.6425)\n",
      "('dvd', 0.7175)\n",
      "('kitchen', 0.75)\n",
      "('apparel', 0.7625)\n",
      "('baby', 0.77)\n",
      "('healthpersonal', 0.775)\n",
      "('cameraphoto', 0.785)\n",
      "fscores\n",
      "('automotive', 0.0)\n",
      "('book', 0.546031746031746)\n",
      "('gourmet', 0.667779632721202)\n",
      "('jewelrywatches', 0.667779632721202)\n",
      "('beauty', 0.6677908937605396)\n",
      "('grocery', 0.66890756302521)\n",
      "('computervideo', 0.6711409395973155)\n",
      "('dvd', 0.6986666666666667)\n",
      "('kitchen', 0.7354497354497355)\n",
      "('apparel', 0.745308310991957)\n",
      "('healthpersonal', 0.7457627118644068)\n",
      "('cameraphoto', 0.7724867724867724)\n",
      "('baby', 0.7973568281938326)\n",
      "distances\n",
      "('cameraphoto', 0.3591191237203061)\n",
      "('kitchen', 0.36080598790800533)\n",
      "('healthpersonal', 0.40402792855433967)\n",
      "('apparel', 0.4178178813904726)\n",
      "('baby', 0.42995757711130556)\n",
      "('computervideo', 0.43407742765602564)\n",
      "('dvd', 0.47610240745966625)\n",
      "('beauty', 0.5043605216094724)\n",
      "('jewelrywatches', 0.5177830939494399)\n",
      "('grocery', 0.5464687545585285)\n",
      "('book', 0.5475787563806471)\n",
      "('automotive', 0.5547142073323208)\n",
      "('gourmet', 0.5612347615826553)\n"
     ]
    }
   ],
   "source": [
    "sorted_Fscores = sorted(Fscores.items(), key=lambda x:x[1])\n",
    "sorted_Accuracies = sorted(Accuracies.items(), key=lambda x:x[1])\n",
    "sorted_euclideandistances = sorted(cosine_distances_toelectronics.items(), key=lambda x:x[1])\n",
    "print \"accuracies\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Accuracies[d]\n",
    "print \"fscores\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Fscores[d]\n",
    "print \"distances\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    #print \"euclidean_distance\"\n",
    "    print sorted_euclideandistances[d]\n",
    "    #print sorted_Fscores[d]\n",
    "    #print sorted_Accuracies[d]\n",
    "    #print sorted_euclideandistances[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "\n",
    "\n",
    "\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.668907563025\n",
      "minority_predictions' model Accuracy\n",
      "0.5075\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.672297297297\n",
      "minority_predictions' model Accuracy\n",
      "0.515\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold = 0.6\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.543130990415\n",
      "minority_predictions' model Accuracy\n",
      "0.6425\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold = 0.7\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.543130990415\n",
      "minority_predictions' model Accuracy\n",
      "0.6425\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold = 0.8\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold = 0.9\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.819587628866\n",
      "majority_predictions' model Accuracy\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.829836829837\n",
      "majority_predictions' model Accuracy\n",
      "0.8175\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.769679300292\n",
      "majority_predictions' model Accuracy\n",
      "0.8025\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold = 0.7\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.536231884058\n",
      "majority_predictions' model Accuracy\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.825316455696\n",
      "majority_predictions' model Accuracy\n",
      "0.8275\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.78313253012\n",
      "majority_predictions' model Accuracy\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.78431372549\n",
      "majority_predictions' model Accuracy\n",
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold = 0.7\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.655737704918\n",
      "majority_predictions' model Accuracy\n",
      "0.7375\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.331950207469\n",
      "majority_predictions' model Accuracy\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Randomly Sampled Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[199.8999749874922,165.17869111964777,103.83640979926068,102.89314845994363,102.24969437607136,100.93562304756433]\n",
    "lowestdistances=[88.87069258197553,94.82615672903758,94.87360012142472,95.0946896519464,95.66085928947116,95.94269122762817]\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','kitchen_predictions','computervideo_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728606356968\n",
      "minority_predictions' model Accuracy\n",
      "0.7225\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.725490196078\n",
      "minority_predictions' model Accuracy\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.483985765125\n",
      "minority_predictions' model Accuracy\n",
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.483985765125\n",
      "minority_predictions' model Accuracy\n",
      "0.6375\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.817102137767\n",
      "majority_predictions' model Accuracy\n",
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.819587628866\n",
      "majority_predictions' model Accuracy\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold = 0.7\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.536231884058\n",
      "majority_predictions' model Accuracy\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.824390243902\n",
      "majority_predictions' model Accuracy\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.81914893617\n",
      "majority_predictions' model Accuracy\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.6\n",
      "majority_predictions' model Accuracy\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.303797468354\n",
      "majority_predictions' model Accuracy\n",
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[0.563039093780797,0.5597066860859891,0.5481744839527478,0.5219070995993643,0.5216979848670661,0.5065087226524536]\n",
    "lowestdistances=[0.3568595161268011,0.3620886835370746,0.4052922274894665,0.4196160338787257,0.4328515918409117,0.4363590979801868]\n",
    "\n",
    "\n",
    "\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['gourmet_predictions','automotive_predictions','grocery_predictions','jewelrywatches_predictions','book_predictions','beauty_predictions']\n",
    "Major_domains = ['kitchen_predictions','cameraphoto_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.668907563025\n",
      "minority_predictions' model Accuracy\n",
      "0.5075\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.672297297297\n",
      "minority_predictions' model Accuracy\n",
      "0.515\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.543130990415\n",
      "minority_predictions' model Accuracy\n",
      "0.6425\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.543130990415\n",
      "minority_predictions' model Accuracy\n",
      "0.6425\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.829836829837\n",
      "majority_predictions' model Accuracy\n",
      "0.8175\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.819587628866\n",
      "majority_predictions' model Accuracy\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.769679300292\n",
      "majority_predictions' model Accuracy\n",
      "0.8025\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold = 0.7\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758823529412\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.536231884058\n",
      "majority_predictions' model Accuracy\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.78313253012\n",
      "majority_predictions' model Accuracy\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold = 0.5\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.825316455696\n",
      "majority_predictions' model Accuracy\n",
      "0.8275\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold = 0.6\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.78431372549\n",
      "majority_predictions' model Accuracy\n",
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold = 0.7\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.655737704918\n",
      "majority_predictions' model Accuracy\n",
      "0.7375\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold = 0.8\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.331950207469\n",
      "majority_predictions' model Accuracy\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold = 0.9\n",
    "electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.863\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.855\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n",
      "max euc acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[199.8999749874922,165.17869111964777,103.83640979926068,102.89314845994363,102.24969437607136,100.93562304756433]\n",
    "    lowestdistances=[88.87069258197553,94.82615672903758,94.87360012142472,95.0946896519464,95.66085928947116,95.94269122762817]\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','kitchen_predictions','computervideo_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.563039093780797,0.5597066860859891,0.5481744839527478,0.5219070995993643,0.5216979848670661,0.5065087226524536]\n",
    "    lowestdistances=[0.3568595161268011,0.3620886835370746,0.4052922274894665,0.4196160338787257,0.4328515918409117,0.4363590979801868]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','grocery_predictions','jewelrywatches_predictions','book_predictions','beauty_predictions']\n",
    "    Major_domains = ['kitchen_predictions','cameraphoto_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_max_acc_euc = 0.8598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_max_acc_cosine = 0.8598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.863\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.855\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n",
      "max euc acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.868\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.86\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.862\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.868, 0.86, 0.859, 0.864, 0.862]\n",
      "max euc acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "euc_avg_th_acc = {}\n",
    "cosine_avg_th_acc = {}\n",
    "euc_avg_th_fscore = {}\n",
    "cosine_avg_th_fscore = {}\n",
    "\n",
    "for t in thresholds:\n",
    "    \n",
    "    euc_avg_th_acc[t] = sum(euc_threshold_acc[t]) / len(euc_threshold_acc[t])\n",
    "    cosine_avg_th_acc[t] = sum(cosine_threshold_acc[t]) / len(cosine_threshold_acc[t])\n",
    "    euc_avg_th_fscore[t] = sum(euc_threshold_fscore[t]) / len(euc_threshold_fscore[t])\n",
    "    cosine_avg_th_fscore[t] = sum(cosine_threshold_fscore[t]) / len(cosine_threshold_fscore[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "average euclidean accuracy\n",
      "0.810733333333\n",
      "average euclidean fscore\n",
      "0.810735114677\n",
      "average cosine accuracy\n",
      "0.6944\n",
      "average cosine fscore\n",
      "0.769412675361\n",
      "0.6\n",
      "average euclidean accuracy\n",
      "0.7868\n",
      "average euclidean fscore\n",
      "0.736102304066\n",
      "average cosine accuracy\n",
      "0.742266666667\n",
      "average cosine fscore\n",
      "0.793655722275\n",
      "0.7\n",
      "average euclidean accuracy\n",
      "0.747466666667\n",
      "average euclidean fscore\n",
      "0.657069868377\n",
      "average cosine accuracy\n",
      "0.766533333333\n",
      "average cosine fscore\n",
      "0.703746434568\n",
      "0.8\n",
      "average euclidean accuracy\n",
      "0.715533333333\n",
      "average euclidean fscore\n",
      "0.5991524391\n",
      "average cosine accuracy\n",
      "0.734733333333\n",
      "average cosine fscore\n",
      "0.650682687114\n",
      "0.9\n",
      "average euclidean accuracy\n",
      "0.603866666667\n",
      "average euclidean fscore\n",
      "0.311161876635\n",
      "average cosine accuracy\n",
      "0.609333333333\n",
      "average cosine fscore\n",
      "0.326149002754\n"
     ]
    }
   ],
   "source": [
    "# across all majority classifiers\n",
    "for t in thresholds:\n",
    "    print t\n",
    "    print \"average euclidean accuracy\"\n",
    "    print euc_avg_th_acc[t]\n",
    "    \n",
    "    print \"average euclidean fscore\"\n",
    "    print euc_avg_th_fscore[t]\n",
    "    \n",
    "    print \"average cosine accuracy\"\n",
    "    print cosine_avg_th_acc[t]\n",
    "    \n",
    "    print \"average cosine fscore\"\n",
    "    print cosine_avg_th_fscore[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "euc_avg_th_acc = {}\n",
    "cosine_avg_th_acc = {}\n",
    "euc_avg_th_fscore = {}\n",
    "cosine_avg_th_fscore = {}\n",
    "\n",
    "for t in thresholds:\n",
    "    \n",
    "    euc_avg_th_acc[t] = sum(euc_threshold_acc[t]) / len(euc_threshold_acc[t])\n",
    "    cosine_avg_th_acc[t] = sum(cosine_threshold_acc[t]) / len(cosine_threshold_acc[t])\n",
    "    euc_avg_th_fscore[t] = sum(euc_threshold_fscore[t]) / len(euc_threshold_fscore[t])\n",
    "    cosine_avg_th_fscore[t] = sum(cosine_threshold_fscore[t]) / len(cosine_threshold_fscore[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "average euclidean accuracy\n",
      "0.854\n",
      "average euclidean fscore\n",
      "0.856172756618\n",
      "average cosine accuracy\n",
      "0.7378\n",
      "average cosine fscore\n",
      "0.787643051859\n",
      "0.6\n",
      "average euclidean accuracy\n",
      "0.8522\n",
      "average euclidean fscore\n",
      "0.838236751449\n",
      "average cosine accuracy\n",
      "0.8626\n",
      "average cosine fscore\n",
      "0.858484039192\n",
      "0.7\n",
      "average euclidean accuracy\n",
      "0.7978\n",
      "average euclidean fscore\n",
      "0.753289900618\n",
      "average cosine accuracy\n",
      "0.8306\n",
      "average cosine fscore\n",
      "0.805052352779\n",
      "0.8\n",
      "average euclidean accuracy\n",
      "0.702\n",
      "average euclidean fscore\n",
      "0.579537612788\n",
      "average cosine accuracy\n",
      "0.7428\n",
      "average cosine fscore\n",
      "0.658255600737\n",
      "0.9\n",
      "average euclidean accuracy\n",
      "0.6006\n",
      "average euclidean fscore\n",
      "0.336192485197\n",
      "average cosine accuracy\n",
      "0.617\n",
      "average cosine fscore\n",
      "0.381153863551\n"
     ]
    }
   ],
   "source": [
    "# across majority-minority classifiers\n",
    "for t in thresholds:\n",
    "    print t\n",
    "    print \"average euclidean accuracy\"\n",
    "    print euc_avg_th_acc[t]\n",
    "    \n",
    "    print \"average euclidean fscore\"\n",
    "    print euc_avg_th_fscore[t]\n",
    "    \n",
    "    print \"average cosine accuracy\"\n",
    "    print cosine_avg_th_acc[t]\n",
    "    \n",
    "    print \"average cosine fscore\"\n",
    "    print cosine_avg_th_fscore[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## least performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.739\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.651\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.741\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.653\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.732\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.653\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.723\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.635\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.747\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.654\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.651, 0.653, 0.653, 0.635, 0.654]\n",
      "max euc acc\n",
      "[0.739, 0.741, 0.732, 0.723, 0.747]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.742\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.651\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.743\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.653\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.735\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.653\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.724\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.635\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.747\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.654\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.651, 0.653, 0.653, 0.635, 0.654]\n",
      "max euc acc\n",
      "[0.742, 0.743, 0.735, 0.724, 0.747]\n"
     ]
    }
   ],
   "source": [
    "##least performing\n",
    "## inverse distance (similarity)\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Top performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.863\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.855\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n",
      "max euc acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.868\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.862\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.86\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.867\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.867\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.857\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.864, 0.858, 0.86, 0.867, 0.857]\n",
      "max euc acc\n",
      "[0.868, 0.858, 0.862, 0.867, 0.855]\n"
     ]
    }
   ],
   "source": [
    "## inverted distance\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and least performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.857\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.868\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.854\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.86\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.851\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.862\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.868, 0.86, 0.859, 0.864, 0.862]\n",
      "max euc acc\n",
      "[0.857, 0.854, 0.851, 0.855, 0.855]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.86\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.868\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.86\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.856\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.862\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.862\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.868, 0.86, 0.859, 0.864, 0.862]\n",
      "max euc acc\n",
      "[0.86, 0.859, 0.856, 0.862, 0.858]\n"
     ]
    }
   ],
   "source": [
    "##inverted distances\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "Fscoress = defaultdict(list)\n",
    "Accuraciess = defaultdict(list)\n",
    "counter=0\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "    Fscores={}\n",
    "    Accuracies={}\n",
    "    book_dist_domains = ['electronics','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    Minor_domains = ['dvd_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    for domain in Minor_domains:\n",
    "        Fscoress[domain].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl[str(domain)]))\n",
    "        Accuraciess[domain].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl[str(domain)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracies for the least performing classifiers\n",
      "dvd_predictions\n",
      "0.7218\n",
      "automotive_predictions\n",
      "0.5004\n",
      "book_predictions\n",
      "0.6466\n",
      "grocery_predictions\n",
      "0.5036\n",
      "jewelrywatches_predictions\n",
      "0.502\n",
      "beauty_predictions\n",
      "0.5036\n"
     ]
    }
   ],
   "source": [
    "print \"average accuracies for the least performing classifiers\"\n",
    "\n",
    "for d in Minor_domains:\n",
    "    print d\n",
    "    print sum(Accuraciess[d]) / len(Accuraciess[d])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "Fscoress = defaultdict(list)\n",
    "Accuraciess = defaultdict(list)\n",
    "counter=0\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "    Fscores={}\n",
    "    Accuracies={}\n",
    "    book_dist_domains = ['electronics','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    for domain in Major_domains:\n",
    "        Fscoress[domain].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl[str(domain)]))\n",
    "        Accuraciess[domain].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl[str(domain)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracies for the least performing classifiers\n",
      "cameraphoto_predictions\n",
      "0.8154\n",
      "kitchen_predictions\n",
      "0.8012\n",
      "healthpersonal_predictions\n",
      "0.794\n",
      "apparel_predictions\n",
      "0.788\n",
      "baby_predictions\n",
      "0.764\n",
      "computervideo_predictions\n",
      "0.5052\n"
     ]
    }
   ],
   "source": [
    "print \"average accuracies for the least performing classifiers\"\n",
    "\n",
    "for d in Major_domains:\n",
    "    print d\n",
    "    print sum(Accuraciess[d]) / len(Accuraciess[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Least performing classifiers (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.508\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.505\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.506\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.503\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.507\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.503\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.505\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.503\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.503\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.502\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.505, 0.503, 0.503, 0.503, 0.502]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.5032\n",
      "average cosine fscore for threshold 0.5\n",
      "0.668092215885\n",
      "max euc acc\n",
      "[0.508, 0.506, 0.507, 0.505, 0.503]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.5058\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.66925533743\n"
     ]
    }
   ],
   "source": [
    "##least performing\n",
    "## inverse distance (similarity)\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores = []\n",
    "max_euc_fscores = []\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Top performing classifiers (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.868\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.864\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.857\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.862\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.86\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.867\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.867\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.857\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.864, 0.858, 0.86, 0.867, 0.857]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.8612\n",
      "average cosine fscore for threshold 0.5\n",
      "0.856478372529\n",
      "max euc acc\n",
      "[0.868, 0.857, 0.862, 0.867, 0.855]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.8618\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.863345804534\n"
     ]
    }
   ],
   "source": [
    "## inverted distance\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores = []\n",
    "max_euc_fscores = []\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and least performing classifiers (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.833\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.827\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.828\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.821\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.828\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.82\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.826\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.822\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.826\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.82\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.827, 0.821, 0.82, 0.822, 0.82]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.822\n",
      "average cosine fscore for threshold 0.5\n",
      "0.840442472391\n",
      "max euc acc\n",
      "[0.833, 0.828, 0.828, 0.826, 0.826]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.8282\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.847447663677\n"
     ]
    }
   ],
   "source": [
    "##inverted distances\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least performing classifiers (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.742\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.505\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.743\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.505\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.735\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.504\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.724\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.505\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.747\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.503\n",
      "data set 5 was tested!\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.5044\n",
      "average cosine fscore for threshold 0.6\n",
      "0.668628166616\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.7382\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.731730234328\n"
     ]
    }
   ],
   "source": [
    "##least performing\n",
    "## inverse distance (similarity)\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "#print \"max cosine acc\"\n",
    "#print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "#print \"max euc acc\"\n",
    "#print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Top performing classifiers (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538755014.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n",
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.863\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.858\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.855\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.8598\n",
      "average cosine fscore for threshold 0.6\n",
      "0.853854961016\n",
      "max euc acc\n",
      "[0.863, 0.858, 0.859, 0.864, 0.855]\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.8598\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.853854961016\n"
     ]
    }
   ],
   "source": [
    "## inverted distance\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and least performing classifiers (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.86\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.868\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.859\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.86\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.856\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.859\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.862\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.864\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.858\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.862\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.868, 0.86, 0.859, 0.864, 0.862]\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.8626\n",
      "average cosine fscore for threshold 0.6\n",
      "0.858484039192\n",
      "max euc acc\n",
      "[0.86, 0.859, 0.856, 0.862, 0.858]\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.859\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.858781064255\n"
     ]
    }
   ],
   "source": [
    "##inverted distances\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least performing classifiers (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.716\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.651\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.729\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.653\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.723\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.653\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.721\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.635\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.722\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.654\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.651, 0.653, 0.653, 0.635, 0.654]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.6492\n",
      "average cosine fscore for threshold 0.7\n",
      "0.516782035336\n",
      "max euc acc\n",
      "[0.716, 0.729, 0.723, 0.721, 0.722]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.7222\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.693577235591\n"
     ]
    }
   ],
   "source": [
    "##least performing\n",
    "## inverse distance (similarity)\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top performing classifiers (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.815\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.815\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.811\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.811\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.815\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.815\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.817\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.817\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.803\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.803\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.815, 0.811, 0.815, 0.817, 0.803]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.8122\n",
      "average cosine fscore for threshold 0.7\n",
      "0.777010425269\n",
      "max euc acc\n",
      "[0.815, 0.811, 0.815, 0.817, 0.803]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.8122\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.777010425269\n"
     ]
    }
   ],
   "source": [
    "## inverted distance\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and least performing classifiers (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.832\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.817\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.834\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.82\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.834\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.825\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.832\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.808\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.821\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.832, 0.834, 0.834, 0.832, 0.821]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.8306\n",
      "average cosine fscore for threshold 0.7\n",
      "0.805052352779\n",
      "max euc acc\n",
      "[0.821, 0.817, 0.82, 0.825, 0.808]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.8182\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.78646075357\n"
     ]
    }
   ],
   "source": [
    "##inverted distances\n",
    "\n",
    "from collections import defaultdict\n",
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions')\n",
    "    else:\n",
    "        electronicstestgl = graphlab.SFrame('electronicstestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[214.9116097375849,165.71662559924397,102.33767634649519,101.41005867269774,100.46890066085126,99.48366700117161]\n",
    "    lowestdistances=[87.44712688247682,93.33273809334,93.70165420097983,93.79765455489812,94.55157322858251,94.66255859631093]\n",
    "\n",
    "    Minor_domains = ['book_predictions','dvd_predictions','gourmet_predictions','grocery_predictions','automotive_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','baby_predictions','healthpersonal_predictions','apparel_predictions','computervideo_predictions','kitchen_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    largestdistances=[0.5612347615826553,0.5547142073323208,0.5475787563806471,0.5464687545585285,0.5177830939494399,0.5043605216094724]\n",
    "    lowestdistances=[0.3591191237203061,0.36080598790800533,0.40402792855433967,0.4178178813904726,0.42995757711130556,0.43407742765602564]\n",
    "    Minor_domains = ['gourmet_predictions','automotive_predictions','book_predictions','grocery_predictions','jewelrywatches_predictions','beauty_predictions']\n",
    "    Major_domains = ['cameraphoto_predictions','kitchen_predictions','healthpersonal_predictions','apparel_predictions','baby_predictions','computervideo_predictions']\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = []\n",
    "    normalized_smallestdistances_inverted = []\n",
    "    for n in normalized_largestdistances:\n",
    "        normalized_largestdistances_inverted.append(1-n)\n",
    "    \n",
    "    for n in normalized_smallestdistances:\n",
    "        normalized_smallestdistances_inverted.append(1-n)\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        electronicstestgl['majority_minority_predictions'] = electronicstestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(electronicstestgl['label'], electronicstestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
