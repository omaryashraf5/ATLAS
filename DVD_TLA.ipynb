{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "#import graphlab\n",
    "import pandas\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import string\n",
    "#xml_data = open('/home/omar/data/train-data/kitchen/positive.review').read()\n",
    "\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            record[subchild.tag] = subchild.text\n",
    "            all_records.append(record)\n",
    "    return pd.DataFrame(all_records)\n",
    "from pathlib2 import Path\n",
    "def extract(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    datacheck=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    review = False\n",
    "    #contents = Path(xml_data).read_text()\n",
    "    for l in File:  #File\n",
    "        l = l.replace('\\n', '')\n",
    "        #l = l.replace(\"'\\u001a'\",'')\n",
    "        \n",
    "    \n",
    "        #l = l.replace('\\t', '')\n",
    "        #l = l.replace('\"', '')\n",
    "        if review and \"</review_text>\" not in l:\n",
    "            revtext+=l\n",
    "            #data.append(l)\n",
    "            \n",
    "        \n",
    "        if \"<review_text>\" in l:\n",
    "            review = True\n",
    "        if \"</review_text>\" in l:\n",
    "            data.append(revtext)\n",
    "            revtext=\"\"\n",
    "            review = False\n",
    "        \n",
    "    return data\n",
    "        \n",
    "\n",
    "\n",
    "def extract_summarized(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    for l in File:\n",
    "        l = l.replace('\\n', '')\n",
    "        \n",
    "        \n",
    "        ##if '<' not in l and '>' not in l and not l.isdigit():\n",
    "            ##data.append(l)\n",
    "        ##if review:\n",
    "            ##data.append(l)\n",
    "            ##review = False\n",
    "        if inreview:\n",
    "            data.append(l)\n",
    "            inreview=False\n",
    "        #\"xxxxABCDyyyy\".find(\"ABCD\") != -1:\n",
    "        if l.find(\"<review_text>\")!=-1:\n",
    "            inreview=True\n",
    "            \n",
    "        #if \"</review_text>\" in l:\n",
    "            #data.append(revtext)\n",
    "            #revtext=\"\"\n",
    "            #inreview=False\n",
    "    return data\n",
    "\n",
    "def Advanced_Extract(xml_data):\n",
    "    #/home/omar/data/train-data/books/positive.review\n",
    "    #\"/home/omar/data/train-data/books/unlabeled.review\"\n",
    "    with open(xml_data) as f:\n",
    "        File = f.readlines()\n",
    "    data=[]\n",
    "    revtext=\"\"\n",
    "    inreview=False\n",
    "    for l in File:\n",
    "        revtext+=l\n",
    "    subtext=\"\"\n",
    "    for word in revtext.split(\" \"):\n",
    "        if inreview:\n",
    "            subtext+=word + \" \"\n",
    "        if \"<review_text> \" in word:\n",
    "            inreview=True\n",
    "        if \"</review_text> \" in word:\n",
    "            inreview=False\n",
    "            data.append(subtext)\n",
    "            subtext=\"\"\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "##original\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "domains = defaultdict(str)\n",
    "domainnames = ['booksgl','electronicsgl','dvdgl','apparelgl','automotivegl','babygl','beautygl','cameraphotogl','computervideo_gamesgl',\n",
    "           'gourmet_foodgl','grocerygl','healthpersonal_caregl','jewelrywatchesgl']\n",
    "\n",
    "import graphlab as gl\n",
    "\n",
    "kitchengl = gl.SFrame('kitechen_reviews.csv')\n",
    "booksgl = gl.SFrame('books_reviews.csv')\n",
    "domains['booksgl'] = booksgl\n",
    "electronicsgl = gl.SFrame('electronics_reviews.csv')\n",
    "domains['electronicsgl'] = electronicsgl\n",
    "dvdgl = gl.SFrame('dvd_reviews.csv')\n",
    "domains['dvdgl'] = dvdgl\n",
    "\n",
    "apparelgl = gl.SFrame('apparel_reviews.csv')\n",
    "domains['apparelgl'] = apparelgl\n",
    "automotivegl = gl.SFrame('automotive_reviews.csv')\n",
    "domains['automotivegl'] = automotivegl\n",
    "babygl = gl.SFrame('baby_reviewsUpdated.csv')\n",
    "domains['babygl'] = babygl\n",
    "\n",
    "beautygl = gl.SFrame('beauty_reviews.csv')\n",
    "domains['beautygl'] = beautygl\n",
    "cameraphotogl = gl.SFrame('cameraphoto_reviews.csv')\n",
    "domains['cameraphotogl'] = cameraphotogl\n",
    "#computervideo_gamesgl = gl.SFrame('computervideo_games_reviews.csv')\n",
    "computervideo_gamesdf = pd.read_csv('computervideo_games_reviews.csv')\n",
    "computervideo_gamesgl = gl.SFrame(data=computervideo_gamesdf)\n",
    "domains['computervideo_gamesgl'] = computervideo_gamesgl\n",
    "\n",
    "gourmet_foodgl = gl.SFrame('gourmet_food_reviews.csv')\n",
    "domains['gourmet_foodgl'] = gourmet_foodgl\n",
    "grocerygl = gl.SFrame('grocery_reviews.csv')\n",
    "domains['grocerygl'] = grocerygl\n",
    "healthpersonal_caregl = gl.SFrame('healthpersonal_care_reviews.csv')\n",
    "domains['healthpersonal_caregl'] = healthpersonal_caregl\n",
    "\n",
    "jewelrywatchesgl = gl.SFrame('jewelrywatches_reviews.csv')\n",
    "domains['jewelrywatchesgl'] = jewelrywatchesgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1537929522.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.046872 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.046872 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\kitechen_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 19856 lines in 0.083702 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 19856 lines in 0.083702 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\books_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\books_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.21659 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.21659 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 54835 lines. Lines per second: 124294</pre>"
      ],
      "text/plain": [
       "Read 54835 lines. Lines per second: 124294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I remember listening to this audio CD about a year ago on the way home from a friend's home in the back country late at night.  I figured what harm could there be... it's about cats... what could Stephen King do there?  Who was I kidding?!  Suffice it to ...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"A most circumspect, articulate and historically (non-revisionist) accurate evaluaton of our political, environmental and practical lives in the US of A today.Important and enlightening info in an age of increasing civil rights suppression and heightened f...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"A most circumspect, articulate and historically (non-revisionist) accurate evaluaton of our political, environmental and practical lives in the US of A today.Important and enlightening info in an age of increasing civil rights suppression and heightened f...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I loved this story all the way through!  I \"\"read\"\" while I drive, so I did the audio CD, (unabridged), and it was delightful!  The storline was so fun and quirky and did have me laughing at so many parts... I do like Maz!  This is a woman we all know!  S...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I loved this story all the way through!  I \"\"read\"\" while I drive, so I did the audio CD, (unabridged), and it was delightful!  The storline was so fun and quirky and did have me laughing at so many parts... I do like Maz!  This is a woman we all know!  S...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"\"I thoroughly enjoyed this book and had a hard time putting it down.  All of the characters were very enjoyable and Natalie aka: Cressida was a gas!  Such a girlfriend!  She was believable, at least in my world!, and I could totally see myself falling into...\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"\"I thoroughly enjoyed this book and had a hard time putting it down.  All of the characters were very enjoyable and Natalie aka: Cressida was a gas!  Such a girlfriend!  She was believable, at least in my world!, and I could totally see myself falling into...\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>5 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "5 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\books_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\books_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 975189 lines in 4.79302 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 975189 lines in 4.79302 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.062492 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.062492 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\electronics_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 23009 lines in 0.096947 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 23009 lines in 0.096947 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.195857 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.195857 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 52466 lines. Lines per second: 118935</pre>"
      ],
      "text/plain": [
       "Read 52466 lines. Lines per second: 118935"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 124438 lines in 0.743053 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 124438 lines in 0.743053 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.015621 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.015621 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\apparel_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 9252 lines in 0.031855 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 9252 lines in 0.031855 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020637 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020637 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\automotive_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 736 lines in 0.019996 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 736 lines in 0.019996 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.031994 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.031994 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\baby_reviewsUpdated.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 4256 lines in 0.036005 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 4256 lines in 0.036005 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.02399 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.02399 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\beauty_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2884 lines in 0.027992 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2884 lines in 0.027992 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.03599 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.03599 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\cameraphoto_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 7408 lines in 0.055439 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 7408 lines in 0.055439 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.015642 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.015642 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\gourmet_food_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1575 lines in 0.010409 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1575 lines in 0.010409 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022848 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022848 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\grocery_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2632 lines in 0.025912 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2632 lines in 0.025912 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.027269 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.027269 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\healthpersonal_care_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 7225 lines in 0.036929 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 7225 lines in 0.036929 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.012604 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.012604 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\jewelrywatches_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1981 lines in 0.012432 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1981 lines in 0.012432 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "##original\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "domains = defaultdict(str)\n",
    "domainnames = ['booksgl','electronicsgl','dvdgl','apparelgl','automotivegl','babygl','beautygl','cameraphotogl','computervideo_gamesgl',\n",
    "           'gourmet_foodgl','grocerygl','healthpersonal_caregl','jewelrywatchesgl']\n",
    "\n",
    "import graphlab as gl\n",
    "\n",
    "kitchengl = gl.SFrame('kitechen_reviews.csv')\n",
    "booksgl = gl.SFrame('books_reviews.csv')\n",
    "domains['booksgl'] = booksgl\n",
    "electronicsgl = gl.SFrame('electronics_reviews.csv')\n",
    "domains['electronicsgl'] = electronicsgl\n",
    "dvdgl = gl.SFrame('dvd_reviews.csv')\n",
    "domains['dvdgl'] = dvdgl\n",
    "\n",
    "apparelgl = gl.SFrame('apparel_reviews.csv')\n",
    "domains['apparelgl'] = apparelgl\n",
    "automotivegl = gl.SFrame('automotive_reviews.csv')\n",
    "domains['automotivegl'] = automotivegl\n",
    "babygl = gl.SFrame('baby_reviewsUpdated.csv')\n",
    "domains['babygl'] = babygl\n",
    "\n",
    "beautygl = gl.SFrame('beauty_reviews.csv')\n",
    "domains['beautygl'] = beautygl\n",
    "cameraphotogl = gl.SFrame('cameraphoto_reviews.csv')\n",
    "domains['cameraphotogl'] = cameraphotogl\n",
    "#computervideo_gamesgl = gl.SFrame('computervideo_games_reviews.csv')\n",
    "computervideo_gamesdf = pd.read_csv('computervideo_games_reviews.csv')\n",
    "computervideo_gamesgl = gl.SFrame(data=computervideo_gamesdf)\n",
    "domains['computervideo_gamesgl'] = computervideo_gamesgl\n",
    "\n",
    "gourmet_foodgl = gl.SFrame('gourmet_food_reviews.csv')\n",
    "domains['gourmet_foodgl'] = gourmet_foodgl\n",
    "grocerygl = gl.SFrame('grocery_reviews.csv')\n",
    "domains['grocerygl'] = grocerygl\n",
    "healthpersonal_caregl = gl.SFrame('healthpersonal_care_reviews.csv')\n",
    "domains['healthpersonal_caregl'] = healthpersonal_caregl\n",
    "\n",
    "jewelrywatchesgl = gl.SFrame('jewelrywatches_reviews.csv')\n",
    "domains['jewelrywatchesgl'] = jewelrywatchesgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#electronicsgl\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "def reviewcleaner(text):\n",
    "    #postags = ['JJ', 'JJR', 'JJS','VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','RB', 'RBR', 'RBS']\n",
    "    postags = ['JJ','VB','RB']\n",
    "    #Nountags = ['NN', 'NNP', 'NNS']\n",
    "    Nountags = ['NN']\n",
    "    #text = \"I love books in general\"\n",
    "\n",
    "    #print words\n",
    "    text = preprocess(text)\n",
    "    raw_words = text.split(\" \")\n",
    "    raw_words2 = text.split(\" \")\n",
    "    #nltk.word_tokenize(text)\n",
    "    try:\n",
    "        words = nltk.pos_tag(raw_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    newsentence=[]\n",
    "    for i in range(len(raw_words)):\n",
    "\n",
    "        #print raw_words[i]\n",
    "        #print words[i][1]\n",
    "        #print words\n",
    "        #print raw_words\n",
    "        ##if len(raw_words) != len(words):\n",
    "            ##print words\n",
    "            ##print raw_words\n",
    "            ##break\n",
    "        if words[i][1] in postags:\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.80 or hsentiments0.neg_score > 0.80:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "            ##newsentence.append(raw_words[i])\n",
    "        elif words[i][1] in Nountags:\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.80 or hsentiments0.neg_score > 0.80:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "    return  (str(\" \".join(newsentence)))\n",
    "\n",
    "def word_counter(textfilepath):\n",
    "    \n",
    "    \n",
    "    #'your_file.txt'\n",
    "    with open(textfilepath) as f:\n",
    "        passage = f.readlines()\n",
    "\n",
    "    words = re.findall(r'\\w+', str(passage))\n",
    "\n",
    "    cap_words = [word.upper() for word in words]\n",
    "\n",
    "    word_counts = Counter(cap_words)\n",
    "    return word_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received kingston 256mb sd card advertised unit came mail exactly 2 days iordered worked perfectly satisfied\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    #sentence = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    ##sentence = \" \".join(filtered_words)\n",
    "    #filtered_words = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    #filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    ##return filtered_words\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "\n",
    "#sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "sentence = \"I received my Kingston 256MB SD card just as advertised.The unit came in the mail exactly 2 days after Iordered. Worked perfectly and I'm very satisfied\"\n",
    "#sentence = \"like many\"\n",
    "print preprocess(sentence)\n",
    "text = preprocess(sentence)\n",
    "raw_words = text.split(\" \")\n",
    "words = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print len(raw_words)\n",
    "print len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\ipykernel\\__main__.py:16: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "dvdgl['clean_review'] = dvdgl['review'].apply(lambda x: reviewcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538275486.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.40127 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.40127 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 52466 lines. Lines per second: 46539.2</pre>"
      ],
      "text/plain": [
       "Read 52466 lines. Lines per second: 46539.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\dvd_reviews.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 124438 lines in 1.70502 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 124438 lines in 1.70502 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "dvdgl = gl.SFrame('dvd_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dvdglpos = dvdgl[dvdgl['label']==1]\n",
    "dvdglneg = dvdgl[dvdgl['label']==0]\n",
    "\n",
    "dvdglpos500 = dvdglpos[:500]\n",
    "dvdglneg500 = dvdglneg[:500]\n",
    "del dvdglpos500['label']\n",
    "del dvdglneg500['label']\n",
    "dvdglpos500.save('dvdglpos500.csv')\n",
    "dvdglneg500.save('dvdglneg500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdglpos500pd = pd.read_csv('dvdglpos500.csv')\n",
    "dvdglneg500pd = pd.read_csv('dvdglneg500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdglpos500pd.to_csv('dvdglpos500pd.txt',index=False)\n",
    "dvdglneg500pd.to_csv('dvdglneg500pd.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdgl_unlabeled = dvdgl[dvdgl['label']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dvdgl_unlabeled['review']\n",
    "del dvdgl_unlabeled['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvdgl_unlabeled['clean_review'] .save(\"dvdglcleanreview_compact_unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicglcleanreview.csv\")\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicglcleanreview_compact.csv\")\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview_compact.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview_compact.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview_compact.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electronics_wordcount = word_counter(\"electronicsgl_compact_unlabeled.csv\")\n",
    "#\n",
    "dvdgl_wordcount = word_counter(\"dvdglcleanreview_compact_unlabeled.csv\")\n",
    "kitchengl_wordcount = word_counter(\"kitchenglcleanreview_compact_unlabeled.csv\")\n",
    "booksgl_wordcount = word_counter(\"booksglcleanreview_compact_unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "apparelgl_wordcount = word_counter(\"apparelglcleanreview_compact2.csv\")\n",
    "automotivegl_wordcount = word_counter(\"automotiveglcleanreview_compact2.csv\")\n",
    "babygl_wordcount = word_counter(\"babyglcleanreview_compact2.csv\")\n",
    "beautygl_wordcount = word_counter(\"beautyglcleanreview_compact2.csv\")\n",
    "cameraphotogl_wordcount = word_counter(\"cameraphotoglcleanreview_compact2.csv\")\n",
    "computervideo_gamesgl_wordcount = word_counter(\"computervideo_gamesglcleanreview_compact2.csv\")\n",
    "gourmet_foodgl_wordcount = word_counter(\"gourmet_foodglcleanreview_compact2.csv\")\n",
    "grocerygl_wordcount = word_counter(\"groceryglcleanreview_compact2.csv\")\n",
    "healthpersonal_caregl_wordcount = word_counter(\"healthpersonal_careglcleanreview_compact2.csv\")\n",
    "jewelrywatchesgl_wordcount = word_counter(\"jewelrywatchesglcleanreview_compact2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dvd_electronics_distance = gl.distances.cosine(electronics_wordcount,dvdgl_wordcount)\n",
    "import graphlab as gl\n",
    "\n",
    "euclidean_distances_todvd={}\n",
    "#kitchen_electronics_distance = gl.distances.euclidean(electronics_wordcount,kitchengl_wordcount)\n",
    "euclidean_distances_todvd['book'] = gl.distances.euclidean(dvdgl_wordcount,booksgl_wordcount)\n",
    "#dvd_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,dvdgl_wordcount)\n",
    "euclidean_distances_todvd['electronics'] = gl.distances.euclidean(dvdgl_wordcount,electronics_wordcount)\n",
    "#books_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,booksgl_wordcount)\n",
    "euclidean_distances_todvd['kitchen'] = gl.distances.euclidean(dvdgl_wordcount,kitchengl_wordcount)\n",
    "\n",
    "#apparel_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,apparelgl_wordcount)\n",
    "euclidean_distances_todvd['apparel'] = gl.distances.euclidean(dvdgl_wordcount,apparelgl_wordcount)\n",
    "#automotive_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,automotivegl_wordcount)\n",
    "euclidean_distances_todvd['automotive'] = gl.distances.euclidean(dvdgl_wordcount,automotivegl_wordcount)\n",
    "#baby_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,babygl_wordcount)\n",
    "euclidean_distances_todvd['baby'] = gl.distances.euclidean(dvdgl_wordcount,babygl_wordcount)\n",
    "#beauty_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,beautygl_wordcount)\n",
    "euclidean_distances_todvd['beauty'] = gl.distances.euclidean(dvdgl_wordcount,beautygl_wordcount)\n",
    "#cameraphoto_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,cameraphotogl_wordcount)\n",
    "euclidean_distances_todvd['cameraphoto'] = gl.distances.euclidean(dvdgl_wordcount,cameraphotogl_wordcount)\n",
    "#computervideo_games_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,computervideo_gamesgl_wordcount)\n",
    "euclidean_distances_todvd['computervideo'] = gl.distances.euclidean(dvdgl_wordcount,computervideo_gamesgl_wordcount)\n",
    "#gourmet_food_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,gourmet_foodgl_wordcount)\n",
    "euclidean_distances_todvd['gourmet'] = gl.distances.euclidean(dvdgl_wordcount,gourmet_foodgl_wordcount)\n",
    "#grocery_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,grocerygl_wordcount)\n",
    "euclidean_distances_todvd['grocery'] = gl.distances.euclidean(dvdgl_wordcount,grocerygl_wordcount)\n",
    "#healthpersonal_care_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,healthpersonal_caregl_wordcount)\n",
    "euclidean_distances_todvd['healthpersonal'] = gl.distances.euclidean(dvdgl_wordcount,healthpersonal_caregl_wordcount)\n",
    "#jewelrywatches_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,jewelrywatchesgl_wordcount)\n",
    "euclidean_distances_todvd['jewelrywatches'] = gl.distances.euclidean(dvdgl_wordcount,jewelrywatchesgl_wordcount)\n",
    "\n",
    "dvd_dist_domains = ['book','electronics','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dvdtestgl = graphlab.SFrame('dvdtestgl_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fscores={}\n",
    "Accuracies={}\n",
    "dvd_dist_domains = ['book','electronics','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    \n",
    "\n",
    "\n",
    "for d in dvd_dist_domains:\n",
    "    Fscores[d] = graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl[str(d)+'_predictions'])\n",
    "    Accuracies[d] = graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl[str(d)+'_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dvd_electronics_distance = gl.distances.cosine(electronics_wordcount,dvdgl_wordcount)\n",
    "#fscore={}\n",
    "#accuracies={}\n",
    "cosine_distances_todvd={}\n",
    "#kitchen_electronics_distance = gl.distances.euclidean(electronics_wordcount,kitchengl_wordcount)\n",
    "cosine_distances_todvd['book'] = gl.distances.cosine(dvdgl_wordcount,booksgl_wordcount)\n",
    "#dvd_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,dvdgl_wordcount)\n",
    "cosine_distances_todvd['electronics'] = gl.distances.cosine(dvdgl_wordcount,electronics_wordcount)\n",
    "#books_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,booksgl_wordcount)\n",
    "cosine_distances_todvd['kitchen'] = gl.distances.cosine(dvdgl_wordcount,kitchengl_wordcount)\n",
    "\n",
    "#apparel_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,apparelgl_wordcount)\n",
    "cosine_distances_todvd['apparel'] = gl.distances.cosine(dvdgl_wordcount,apparelgl_wordcount)\n",
    "#automotive_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,automotivegl_wordcount)\n",
    "cosine_distances_todvd['automotive'] = gl.distances.cosine(dvdgl_wordcount,automotivegl_wordcount)\n",
    "#baby_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,babygl_wordcount)\n",
    "cosine_distances_todvd['baby'] = gl.distances.cosine(dvdgl_wordcount,babygl_wordcount)\n",
    "#beauty_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,beautygl_wordcount)\n",
    "cosine_distances_todvd['beauty'] = gl.distances.cosine(dvdgl_wordcount,beautygl_wordcount)\n",
    "#cameraphoto_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,cameraphotogl_wordcount)\n",
    "cosine_distances_todvd['cameraphoto'] = gl.distances.cosine(dvdgl_wordcount,cameraphotogl_wordcount)\n",
    "#computervideo_games_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,computervideo_gamesgl_wordcount)\n",
    "cosine_distances_todvd['computervideo'] = gl.distances.cosine(dvdgl_wordcount,computervideo_gamesgl_wordcount)\n",
    "#gourmet_food_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,gourmet_foodgl_wordcount)\n",
    "cosine_distances_todvd['gourmet'] = gl.distances.cosine(dvdgl_wordcount,gourmet_foodgl_wordcount)\n",
    "#grocery_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,grocerygl_wordcount)\n",
    "cosine_distances_todvd['grocery'] = gl.distances.cosine(dvdgl_wordcount,grocerygl_wordcount)\n",
    "#healthpersonal_care_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,healthpersonal_caregl_wordcount)\n",
    "cosine_distances_todvd['healthpersonal'] = gl.distances.cosine(dvdgl_wordcount,healthpersonal_caregl_wordcount)\n",
    "#jewelrywatches_kitchen_distance = gl.distances.euclidean(kitchengl_wordcount,jewelrywatchesgl_wordcount)\n",
    "cosine_distances_todvd['jewelrywatches'] = gl.distances.cosine(dvdgl_wordcount,jewelrywatchesgl_wordcount)\n",
    "\n",
    "dvd_dist_domains = ['book','electronics','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "('grocery', 0.5)\n",
      "('beauty', 0.5)\n",
      "('gourmet', 0.5)\n",
      "('automotive', 0.5)\n",
      "('computervideo', 0.5)\n",
      "('jewelrywatches', 0.5025)\n",
      "('baby', 0.595)\n",
      "('apparel', 0.6775)\n",
      "('healthpersonal', 0.69)\n",
      "('cameraphoto', 0.6975)\n",
      "('kitchen', 0.6975)\n",
      "('book', 0.7)\n",
      "('electronics', 0.7125)\n",
      "fscores\n",
      "('automotive', 0.0)\n",
      "('book', 0.6319018404907976)\n",
      "('grocery', 0.6655518394648829)\n",
      "('beauty', 0.6655518394648829)\n",
      "('gourmet', 0.6666666666666666)\n",
      "('computervideo', 0.6666666666666666)\n",
      "('jewelrywatches', 0.667779632721202)\n",
      "('healthpersonal', 0.6770833333333333)\n",
      "('apparel', 0.6783042394014963)\n",
      "('baby', 0.6872586872586872)\n",
      "('cameraphoto', 0.7012345679012345)\n",
      "('electronics', 0.7103274559193954)\n",
      "('kitchen', 0.7256235827664399)\n",
      "distances\n",
      "('book', 156.70035098875815)\n",
      "('electronics', 165.71662559924397)\n",
      "('kitchen', 167.77067681809)\n",
      "('healthpersonal', 174.79702514631077)\n",
      "('cameraphoto', 175.775424903483)\n",
      "('apparel', 176.07952748687168)\n",
      "('computervideo', 176.351920885484)\n",
      "('baby', 179.2567990342347)\n",
      "('beauty', 180.8065264308786)\n",
      "('grocery', 183.26483568868306)\n",
      "('gourmet', 183.5619786339208)\n",
      "('jewelrywatches', 185.06215172206336)\n",
      "('automotive', 186.884991371699)\n"
     ]
    }
   ],
   "source": [
    "sorted_Fscores = sorted(Fscores.items(), key=lambda x:x[1])\n",
    "sorted_Accuracies = sorted(Accuracies.items(), key=lambda x:x[1])\n",
    "sorted_euclideandistances = sorted(euclidean_distances_todvd.items(), key=lambda x:x[1])\n",
    "print \"accuracies\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Accuracies[d]\n",
    "print \"fscores\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Fscores[d]\n",
    "print \"distances\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    #print \"euclidean_distance\"\n",
    "    print sorted_euclideandistances[d]\n",
    "    #print sorted_Fscores[d]\n",
    "    #print sorted_Accuracies[d]\n",
    "    #print sorted_euclideandistances[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[186.884991371699,185.06215172206336,183.5619786339208,183.26483568868306,180.8065264308786,179.2567990342347]\n",
    "lowestdistances=[156.70035098875815,165.71662559924397,167.77067681809,174.79702514631077,175.775424903483,176.07952748687168]\n",
    "\n",
    "#largestdistances=[224.6686448973243,223.1456923178218,221.84003245582164,221.53103620034824,219.36499264923745,217.89217516927954]\n",
    "#lowestdistances=[172.89881433948585,193.2744163100745,195.2255106280939,214.01869077255847,215.05115670463155,215.25798475317936]\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.667779632721\n",
      "minority_predictions' model Accuracy\n",
      "0.5025\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.665551839465\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.684719535783\n",
      "minority_predictions' model Accuracy\n",
      "0.5925\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.684719535783\n",
      "minority_predictions' model Accuracy\n",
      "0.5925\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.758620689655\n",
      "majority_predictions' model Accuracy\n",
      "0.755\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.735694822888\n",
      "majority_predictions' model Accuracy\n",
      "0.7575\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.590163934426\n",
      "majority_predictions' model Accuracy\n",
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.590163934426\n",
      "majority_predictions' model Accuracy\n",
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.309623430962\n",
      "majority_predictions' model Accuracy\n",
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.761523046092\n",
      "majority_predictions' model Accuracy\n",
      "0.7025\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.788321167883\n",
      "majority_predictions' model Accuracy\n",
      "0.7825\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.716666666667\n",
      "majority_predictions' model Accuracy\n",
      "0.745\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.582781456954\n",
      "majority_predictions' model Accuracy\n",
      "0.685\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.309623430962\n",
      "majority_predictions' model Accuracy\n",
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the above experiments using cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "('grocery', 0.5)\n",
      "('beauty', 0.5)\n",
      "('gourmet', 0.5)\n",
      "('automotive', 0.5)\n",
      "('computervideo', 0.5)\n",
      "('jewelrywatches', 0.5025)\n",
      "('baby', 0.595)\n",
      "('apparel', 0.6775)\n",
      "('healthpersonal', 0.69)\n",
      "('cameraphoto', 0.6975)\n",
      "('kitchen', 0.6975)\n",
      "('book', 0.7)\n",
      "('electronics', 0.7125)\n",
      "fscores\n",
      "('automotive', 0.0)\n",
      "('book', 0.6319018404907976)\n",
      "('grocery', 0.6655518394648829)\n",
      "('beauty', 0.6655518394648829)\n",
      "('gourmet', 0.6666666666666666)\n",
      "('computervideo', 0.6666666666666666)\n",
      "('jewelrywatches', 0.667779632721202)\n",
      "('healthpersonal', 0.6770833333333333)\n",
      "('apparel', 0.6783042394014963)\n",
      "('baby', 0.6872586872586872)\n",
      "('cameraphoto', 0.7012345679012345)\n",
      "('electronics', 0.7103274559193954)\n",
      "('kitchen', 0.7256235827664399)\n",
      "distances\n",
      "('book', 0.23901334588341028)\n",
      "('electronics', 0.47610240745966625)\n",
      "('kitchen', 0.49261932743957626)\n",
      "('healthpersonal', 0.5626394312464831)\n",
      "('cameraphoto', 0.5744053489333231)\n",
      "('apparel', 0.577554111313622)\n",
      "('computervideo', 0.5813648740047752)\n",
      "('baby', 0.6149975256684418)\n",
      "('beauty', 0.6344634706465471)\n",
      "('grocery', 0.6689072591500338)\n",
      "('gourmet', 0.6733451582659224)\n",
      "('jewelrywatches', 0.6970753286926971)\n",
      "('automotive', 0.7284356711936366)\n"
     ]
    }
   ],
   "source": [
    "sorted_Fscores = sorted(Fscores.items(), key=lambda x:x[1])\n",
    "sorted_Accuracies = sorted(Accuracies.items(), key=lambda x:x[1])\n",
    "sorted_cosinedistances = sorted(cosine_distances_todvd.items(), key=lambda x:x[1])\n",
    "print \"accuracies\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Accuracies[d]\n",
    "print \"fscores\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    print sorted_Fscores[d]\n",
    "print \"distances\"\n",
    "for d in range(len(sorted_Fscores)):\n",
    "    #print \"euclidean_distance\"\n",
    "    print sorted_cosinedistances[d]\n",
    "    #print sorted_Fscores[d]\n",
    "    #print sorted_Accuracies[d]\n",
    "    #print sorted_euclideandistances[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[0.7284356711936366,0.6970753286926971, 0.6733451582659224,0.6689072591500338,0.6344634706465471,0.6149975256684418]\n",
    "lowestdistances=[0.23901334588341028,0.47610240745966625,0.49261932743957626,0.5626394312464831,0.5744053489333231,0.577554111313622]\n",
    "\n",
    "#largestdistances=[ 0.7690976436058181,0.7428504560012771, 0.7222205618125017,0.7176459518562364,0.6873738157596396,0.6688492021600079]\n",
    "#lowestdistances=[0.26233362308000074,0.45084920869462275,0.462982751863136,0.6237263172537725,0.6355717707205912,0.6377743940887945]\n",
    "\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.667779632721\n",
      "minority_predictions' model Accuracy\n",
      "0.5025\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.665551839465\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.684719535783\n",
      "minority_predictions' model Accuracy\n",
      "0.5925\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.684719535783\n",
      "minority_predictions' model Accuracy\n",
      "0.5925\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.774818401937\n",
      "majority_predictions' model Accuracy\n",
      "0.7675\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.735694822888\n",
      "majority_predictions' model Accuracy\n",
      "0.7575\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.666666666667\n",
      "majority_predictions' model Accuracy\n",
      "0.7175\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.590163934426\n",
      "majority_predictions' model Accuracy\n",
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.441947565543\n",
      "majority_predictions' model Accuracy\n",
      "0.6275\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.76\n",
      "majority_predictions' model Accuracy\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.791569086651\n",
      "majority_predictions' model Accuracy\n",
      "0.7775\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.71270718232\n",
      "majority_predictions' model Accuracy\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.582781456954\n",
      "majority_predictions' model Accuracy\n",
      "0.685\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.309623430962\n",
      "majority_predictions' model Accuracy\n",
      "0.5875\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## top DVD accuracy -> 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Randomly Sampled Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dvdtestgl = gl.SFrame('dvdtestgl_random_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.666666666667\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.668449197861\n",
      "minority_predictions' model Accuracy\n",
      "0.504\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728110599078\n",
      "minority_predictions' model Accuracy\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728110599078\n",
      "minority_predictions' model Accuracy\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.797230464886\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.80479825518\n",
      "majority_predictions' model Accuracy\n",
      "0.821\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.669250645995\n",
      "majority_predictions' model Accuracy\n",
      "0.744\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.669250645995\n",
      "majority_predictions' model Accuracy\n",
      "0.744\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.379421221865\n",
      "majority_predictions' model Accuracy\n",
      "0.614\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.774405250205\n",
      "majority_predictions' model Accuracy\n",
      "0.725\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.811339198436\n",
      "majority_predictions' model Accuracy\n",
      "0.807\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.800438596491\n",
      "majority_predictions' model Accuracy\n",
      "0.818\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.660598179454\n",
      "majority_predictions' model Accuracy\n",
      "0.739\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.376811594203\n",
      "majority_predictions' model Accuracy\n",
      "0.613\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec\n",
    "\n",
    "##largestdistances=[215.11624764298952,193.2744163100745,133.07892395116517,128.80993750483694,127.95702403541588,125.9563416426501,125.88089608832628]\n",
    "##lowestdistances=[0.339159452128,0.457601529338,0.462982751863,0.488780265727,0.491315411726,0.503708849348]\n",
    "##lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "##highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "##lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "#############################\n",
    "#euclidean\n",
    "\n",
    "#largestdistances=[242.34066930666012,237.49947368362734,235.84104816592043,235.54617381736432,233.4159377591856,232.7294566658892,230.5970511520041]\n",
    "largestdistances=[0.728378766949138,0.6973479044077687, 0.6735007371811207,0.6689207812322693,0.6344883193637219,0.6149306806256589]\n",
    "lowestdistances=[0.220478158447052,0.4698293279951744,0.485696773208683,0.5626561706013959,0.5746715005285852,0.5774048543133117]\n",
    "lowestdist_errors =[0.21,0.2125,0.255,0.225,0.20375,0.23]\n",
    "highestdist_errors =[0.4925,0.4625,0.485,0.45125,0.44125,0.47125]\n",
    "lowestdist_weights = compute_weights(lowestdist_errors)\n",
    "\n",
    "##############################\n",
    "highestdist_weights = compute_weights(highestdist_errors)\n",
    "Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "normalized_smallestdistances = euclidean_norm_dict(lowestdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.667111407605\n",
      "minority_predictions' model Accuracy\n",
      "0.501\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.668449197861\n",
      "minority_predictions' model Accuracy\n",
      "0.504\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728110599078\n",
      "minority_predictions' model Accuracy\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#0.7 threshold\n",
    "threshold=0.7\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.728110599078\n",
      "minority_predictions' model Accuracy\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#0.8 threshold\n",
    "threshold=0.8\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minority_predictions' model Fscore\n",
      "0.0\n",
      "minority_predictions' model Accuracy\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "print \"minority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions'])\n",
    "print \"minority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.797230464886\n",
      "majority_predictions' model Accuracy\n",
      "0.795\n"
     ]
    }
   ],
   "source": [
    "#0.5 threshold\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.80479825518\n",
      "majority_predictions' model Accuracy\n",
      "0.821\n"
     ]
    }
   ],
   "source": [
    "#0.6 threshold\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.54415954416\n",
      "majority_predictions' model Accuracy\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#0.9 threshold\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.773770491803\n",
      "majority_predictions' model Accuracy\n",
      "0.724\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.5 using all models\n",
    "threshold=0.5\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.80534351145\n",
      "majority_predictions' model Accuracy\n",
      "0.796\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.6 using all models\n",
    "threshold=0.6\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.802617230098\n",
      "majority_predictions' model Accuracy\n",
      "0.819\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.7 using all models\n",
    "threshold=0.7\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.660598179454\n",
      "majority_predictions' model Accuracy\n",
      "0.739\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.8 using all models\n",
    "threshold=0.8\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_predictions' model Fscore\n",
      "0.376811594203\n",
      "majority_predictions' model Accuracy\n",
      "0.613\n"
     ]
    }
   ],
   "source": [
    "#threshold 0.9 using all models\n",
    "threshold=0.9\n",
    "dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "print \"majority_predictions' model Fscore\"\n",
    "print graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])\n",
    "print \"majority_predictions' model Accuracy\"\n",
    "print graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#largestdistances\n",
    "#Minor_domains\n",
    "\n",
    "def weighted_predict_largedist(sframe,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_largestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #Major_domains\n",
    "\n",
    "def weighted_predict_smalldist(sframe,normalized_smallestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    weighted_neg_predictions = weighted_neg_predictions*-1\n",
    "    totalweight=sum(normalized_smallestdistances)\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def weighted_predict_smalldist_largedistances(sframe,normalized_smallestdistances,normalized_largestdistances,threshold):\n",
    "    weighted_pos_predictions=0\n",
    "    weighted_neg_predictions=0\n",
    "    for i in range(len(Major_domains)):\n",
    "        weighted_pos_predictions+=normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_smallestdistances[i]*sframe[Major_domains[i]]\n",
    "    for i in range(len(Minor_domains)):\n",
    "        weighted_pos_predictions+=normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "        weighted_neg_predictions+= normalized_largestdistances[i]*sframe[Minor_domains[i]]\n",
    "    weight1=sum(normalized_smallestdistances)\n",
    "    weight2=sum(normalized_largestdistances)\n",
    "    totalweight = weight1 + weight2\n",
    "    if weighted_pos_predictions>(totalweight*threshold): #weighted_neg_predictions<weighted_pos_predictions:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm\n",
    "def compute_weights(vec):\n",
    "    newvec=[]\n",
    "    for v in vec:\n",
    "        e = (1-v) / v\n",
    "        weight = (1/2) * np.log(e)\n",
    "        newvec.append(weight)\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.821\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.79\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.786\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
      "max euc acc\n",
      "[0.821, 0.79, 0.807, 0.791, 0.807]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.728378766949138,0.6973479044077687, 0.6735007371811207,0.6689207812322693,0.6344883193637219,0.6149306806256589]\n",
    "    lowestdistances=[0.220478158447052,0.4698293279951744,0.485696773208683,0.5626561706013959,0.5746715005285852,0.5774048543133117]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_max_acc_euc = 0.8032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_max_acc_cosine = 0.8022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538017997.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n",
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.821\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.79\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.786\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
      "max euc acc\n",
      "[0.821, 0.79, 0.807, 0.791, 0.807]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[186.884991371699,185.06215172206336,183.5619786339208,183.26483568868306,180.8065264308786,179.2567990342347]\n",
    "    lowestdistances=[156.70035098875815,165.71662559924397,167.77067681809,174.79702514631077,175.775424903483,176.07952748687168]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    largestdistances=[0.7284356711936366,0.6970753286926971, 0.6733451582659224,0.6689072591500338,0.6344634706465471,0.6149975256684418]\n",
    "    lowestdistances=[0.23901334588341028,0.47610240745966625,0.49261932743957626,0.5626394312464831,0.5744053489333231,0.577554111313622]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.821\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.79\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.821, 0.79, 0.807, 0.791, 0.807]\n",
      "max euc acc\n",
      "[0.821, 0.79, 0.807, 0.791, 0.807]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "euc_avg_th_acc = {}\n",
    "cosine_avg_th_acc = {}\n",
    "euc_avg_th_fscore = {}\n",
    "cosine_avg_th_fscore = {}\n",
    "\n",
    "for t in thresholds:\n",
    "    \n",
    "    euc_avg_th_acc[t] = sum(euc_threshold_acc[t]) / len(euc_threshold_acc[t])\n",
    "    cosine_avg_th_acc[t] = sum(cosine_threshold_acc[t]) / len(cosine_threshold_acc[t])\n",
    "    euc_avg_th_fscore[t] = sum(euc_threshold_fscore[t]) / len(euc_threshold_fscore[t])\n",
    "    cosine_avg_th_fscore[t] = sum(cosine_threshold_fscore[t]) / len(cosine_threshold_fscore[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "average euclidean accuracy\n",
      "0.666466666667\n",
      "average euclidean fscore\n",
      "0.741202893149\n",
      "average cosine accuracy\n",
      "0.666466666667\n",
      "average cosine fscore\n",
      "0.741202893149\n",
      "0.6\n",
      "average euclidean accuracy\n",
      "0.701066666667\n",
      "average euclidean fscore\n",
      "0.751600728329\n",
      "average cosine accuracy\n",
      "0.701066666667\n",
      "average cosine fscore\n",
      "0.751600728329\n",
      "0.7\n",
      "average euclidean accuracy\n",
      "0.731\n",
      "average euclidean fscore\n",
      "0.725156957339\n",
      "average cosine accuracy\n",
      "0.731\n",
      "average cosine fscore\n",
      "0.725156957339\n",
      "0.8\n",
      "average euclidean accuracy\n",
      "0.7104\n",
      "average euclidean fscore\n",
      "0.686131885726\n",
      "average cosine accuracy\n",
      "0.7104\n",
      "average cosine fscore\n",
      "0.686131885726\n",
      "0.9\n",
      "average euclidean accuracy\n",
      "0.575066666667\n",
      "average euclidean fscore\n",
      "0.249299230234\n",
      "average cosine accuracy\n",
      "0.575066666667\n",
      "average cosine fscore\n",
      "0.249299230234\n"
     ]
    }
   ],
   "source": [
    "# across all majority classifiers\n",
    "for t in thresholds:\n",
    "    print t\n",
    "    print \"average euclidean accuracy\"\n",
    "    print euc_avg_th_acc[t]\n",
    "    \n",
    "    print \"average euclidean fscore\"\n",
    "    print euc_avg_th_fscore[t]\n",
    "    \n",
    "    print \"average cosine accuracy\"\n",
    "    print cosine_avg_th_acc[t]\n",
    "    \n",
    "    print \"average cosine fscore\"\n",
    "    print cosine_avg_th_fscore[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "euc_avg_th_acc = {}\n",
    "cosine_avg_th_acc = {}\n",
    "euc_avg_th_fscore = {}\n",
    "cosine_avg_th_fscore = {}\n",
    "\n",
    "for t in thresholds:\n",
    "    \n",
    "    euc_avg_th_acc[t] = sum(euc_threshold_acc[t]) / len(euc_threshold_acc[t])\n",
    "    cosine_avg_th_acc[t] = sum(cosine_threshold_acc[t]) / len(cosine_threshold_acc[t])\n",
    "    euc_avg_th_fscore[t] = sum(euc_threshold_fscore[t]) / len(euc_threshold_fscore[t])\n",
    "    cosine_avg_th_fscore[t] = sum(cosine_threshold_fscore[t]) / len(cosine_threshold_fscore[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "average euclidean accuracy\n",
      "0.7118\n",
      "average euclidean fscore\n",
      "0.765670165132\n",
      "average cosine accuracy\n",
      "0.7118\n",
      "average cosine fscore\n",
      "0.765670165132\n",
      "0.6\n",
      "average euclidean accuracy\n",
      "0.7982\n",
      "average euclidean fscore\n",
      "0.803490560887\n",
      "average cosine accuracy\n",
      "0.7982\n",
      "average cosine fscore\n",
      "0.803490560887\n",
      "0.7\n",
      "average euclidean accuracy\n",
      "0.8002\n",
      "average euclidean fscore\n",
      "0.777878471935\n",
      "average cosine accuracy\n",
      "0.8002\n",
      "average cosine fscore\n",
      "0.777878471935\n",
      "0.8\n",
      "average euclidean accuracy\n",
      "0.7384\n",
      "average euclidean fscore\n",
      "0.660803257097\n",
      "average cosine accuracy\n",
      "0.7384\n",
      "average cosine fscore\n",
      "0.660803257097\n",
      "0.9\n",
      "average euclidean accuracy\n",
      "0.612\n",
      "average euclidean fscore\n",
      "0.372385834592\n",
      "average cosine accuracy\n",
      "0.612\n",
      "average cosine fscore\n",
      "0.372385834592\n"
     ]
    }
   ],
   "source": [
    "# across majority-minority classifiers\n",
    "for t in thresholds:\n",
    "    print t\n",
    "    print \"average euclidean accuracy\"\n",
    "    print euc_avg_th_acc[t]\n",
    "    \n",
    "    print \"average euclidean fscore\"\n",
    "    print euc_avg_th_fscore[t]\n",
    "    \n",
    "    print \"average cosine accuracy\"\n",
    "    print cosine_avg_th_acc[t]\n",
    "    \n",
    "    print \"average cosine fscore\"\n",
    "    print cosine_avg_th_fscore[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Performing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.646\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.646\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.659\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.659\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.645\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.645\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.657\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.657\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.648\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.648\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n",
      "max euc acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.646\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.646\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.659\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.659\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.645\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.645\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.657\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.657\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.648\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.648\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n",
      "max euc acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max cosine acc\n",
    "[0.646, 0.659, 0.645, 0.657, 0.648]\n",
    "max euc acc\n",
    "[0.646, 0.659, 0.645, 0.657, 0.648]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.821\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.79\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.786\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.786\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.807\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
      "max euc acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.829\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.829\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.797\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.797\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.81\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.81\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.814\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.814\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.829, 0.797, 0.81, 0.791, 0.814]\n",
      "max euc acc\n",
      "[0.829, 0.797, 0.81, 0.791, 0.814]\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max cosine acc\n",
    "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
    "max euc acc\n",
    "[0.821, 0.79, 0.807, 0.786, 0.807]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and least performing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.818\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.818\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.789\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.789\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.803\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.803\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.805\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.805\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.818, 0.789, 0.803, 0.791, 0.805]\n",
      "max euc acc\n",
      "[0.818, 0.789, 0.803, 0.791, 0.805]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538541321.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n",
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.818\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.818\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.789\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.789\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.803\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.803\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.805\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "max euc acc\n",
      "0.805\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.818, 0.789, 0.803, 0.791, 0.805]\n",
      "max euc acc\n",
      "[0.818, 0.789, 0.803, 0.791, 0.805]\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "import graphlab\n",
    "        \n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max cosine acc\n",
    "[0.818, 0.789, 0.803, 0.791, 0.805]\n",
    "max euc acc\n",
    "[0.818, 0.789, 0.803, 0.791, 0.805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "from collections import defaultdict\n",
    "Fscoress = defaultdict(list)\n",
    "Accuraciess = defaultdict(list)\n",
    "counter=0\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "    Fscores={}\n",
    "    Accuracies={}\n",
    "    book_dist_domains = ['electronics','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    for domain in Minor_domains:\n",
    "        Fscoress[domain].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl[str(domain)]))\n",
    "        Accuraciess[domain].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl[str(domain)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracies for the least performing classifiers\n",
      "automotive_predictions\n",
      "0.5\n",
      "jewelrywatches_predictions\n",
      "0.5002\n",
      "gourmet_predictions\n",
      "0.5\n",
      "grocery_predictions\n",
      "0.501\n",
      "beauty_predictions\n",
      "0.502\n",
      "baby_predictions\n",
      "0.651\n"
     ]
    }
   ],
   "source": [
    "print \"average accuracies for the least performing classifiers\"\n",
    "\n",
    "for d in Minor_domains:\n",
    "    print d\n",
    "    print sum(Accuraciess[d]) / len(Accuraciess[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = [0.5,0.6,0.7,0.8,0.9]\n",
    "from collections import defaultdict\n",
    "Fscoress = defaultdict(list)\n",
    "Accuraciess = defaultdict(list)\n",
    "counter=0\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "    Fscores={}\n",
    "    Accuracies={}\n",
    "    book_dist_domains = ['electronics','dvd','kitchen','apparel','automotive','baby','beauty','cameraphoto','computervideo','gourmet','grocery','healthpersonal','jewelrywatches']\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    for domain in Major_domains:\n",
    "        Fscoress[domain].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl[str(domain)]))\n",
    "        Accuraciess[domain].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl[str(domain)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracies for the least performing classifiers\n",
      "book_predictions\n",
      "0.7268\n",
      "electronics_predictions\n",
      "0.7186\n",
      "kitchen_predictions\n",
      "0.7002\n",
      "healthpersonal_predictions\n",
      "0.738\n",
      "cameraphoto_predictions\n",
      "0.7082\n",
      "apparel_predictions\n",
      "0.7374\n"
     ]
    }
   ],
   "source": [
    "print \"average accuracies for the least performing classifiers\"\n",
    "\n",
    "for d in Major_domains:\n",
    "    print d\n",
    "    print sum(Accuraciess[d]) / len(Accuraciess[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Least Performing (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1538695353.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n",
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.504\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.504\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.503\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.503\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.505\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.505\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.501\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.501\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.501\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.501\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.504, 0.503, 0.505, 0.501, 0.501]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.5028\n",
      "average cosine fscore for threshold 0.5\n",
      "0.66791420123\n",
      "max euc acc\n",
      "[0.504, 0.503, 0.505, 0.501, 0.501]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.5028\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.66791420123\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Performing (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.829\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.829\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.797\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.797\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.81\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.81\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.814\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.814\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.829, 0.797, 0.81, 0.791, 0.814]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.8082\n",
      "average cosine fscore for threshold 0.5\n",
      "0.794707416353\n",
      "max euc acc\n",
      "[0.829, 0.797, 0.81, 0.791, 0.814]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.8082\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.794707416353\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and Least Performing (th=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.735\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.735\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.728\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.728\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.729\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.729\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.73\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.73\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.744\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.744\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.735, 0.728, 0.729, 0.73, 0.744]\n",
      "average cosine accuracy for threshold 0.5\n",
      "0.7332\n",
      "average cosine fscore for threshold 0.5\n",
      "0.776471996174\n",
      "max euc acc\n",
      "[0.735, 0.728, 0.729, 0.73, 0.744]\n",
      "average euclidean accuracy for threshold 0.5\n",
      "0.7332\n",
      "average euclidean fscore for threshold 0.5\n",
      "0.776471996174\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "import graphlab\n",
    "        \n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.5]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Performing (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.504\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.504\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.503\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.503\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.505\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.505\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.501\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.501\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.501\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.501\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.504, 0.503, 0.505, 0.501, 0.501]\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.5028\n",
      "average cosine fscore for threshold 0.6\n",
      "0.66791420123\n",
      "max euc acc\n",
      "[0.504, 0.503, 0.505, 0.501, 0.501]\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.5028\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.66791420123\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Performing (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.821\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.79\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.807\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.786\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.786\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.807\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.8022\n",
      "average cosine fscore for threshold 0.6\n",
      "0.783397422868\n",
      "max euc acc\n",
      "[0.821, 0.79, 0.807, 0.786, 0.807]\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.8022\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.783397422868\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and Least Performing (th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.807\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.807\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.789\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.789\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.799\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.799\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.791\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.805\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.805\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.807, 0.789, 0.799, 0.791, 0.805]\n",
      "average cosine accuracy for threshold 0.6\n",
      "0.7982\n",
      "average cosine fscore for threshold 0.6\n",
      "0.803490560887\n",
      "max euc acc\n",
      "[0.807, 0.789, 0.799, 0.791, 0.805]\n",
      "average euclidean accuracy for threshold 0.6\n",
      "0.7982\n",
      "average euclidean fscore for threshold 0.6\n",
      "0.803490560887\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "import graphlab\n",
    "        \n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.6]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Performing (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.646\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.646\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.659\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.659\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.645\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.645\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.657\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.657\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.648\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.648\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.651\n",
      "average cosine fscore for threshold 0.7\n",
      "0.730253234121\n",
      "max euc acc\n",
      "[0.646, 0.659, 0.645, 0.657, 0.648]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.651\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.730253234121\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    \n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances_inverted,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Performing (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.744\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.744\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.731\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.731\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.75\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.75\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.731\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.731\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.753\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.753\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.744, 0.731, 0.75, 0.731, 0.753]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.7418\n",
      "average cosine fscore for threshold 0.7\n",
      "0.667339165961\n",
      "max euc acc\n",
      "[0.744, 0.731, 0.75, 0.731, 0.753]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.7418\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.667339165961\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances_inverted,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances,normalized_largestdistances,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and Least Performing (th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for random dataset 1\n",
      "euclidean distance results for the minority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority classifiers of random dataset 1\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.818\n",
      "Cosine distance results for the minority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority classifiers of random dataset 1\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 1\n",
      "max euc acc\n",
      "0.818\n",
      "data set 1 was tested!\n",
      "results for random dataset 2\n",
      "euclidean distance results for the minority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority classifiers of random dataset 2\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.788\n",
      "Cosine distance results for the minority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority classifiers of random dataset 2\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 2\n",
      "max euc acc\n",
      "0.788\n",
      "data set 2 was tested!\n",
      "results for random dataset 3\n",
      "euclidean distance results for the minority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority classifiers of random dataset 3\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.803\n",
      "Cosine distance results for the minority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority classifiers of random dataset 3\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 3\n",
      "max euc acc\n",
      "0.803\n",
      "data set 3 was tested!\n",
      "results for random dataset 4\n",
      "euclidean distance results for the minority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority classifiers of random dataset 4\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.789\n",
      "Cosine distance results for the minority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority classifiers of random dataset 4\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 4\n",
      "max euc acc\n",
      "0.789\n",
      "data set 4 was tested!\n",
      "results for random dataset 5\n",
      "euclidean distance results for the minority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority classifiers of random dataset 5\n",
      "euclidean distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.803\n",
      "Cosine distance results for the minority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority classifiers of random dataset 5\n",
      "Cosine distance results for the Majority-Minority classifiers of random dataset 5\n",
      "max euc acc\n",
      "0.803\n",
      "data set 5 was tested!\n",
      "max cosine acc\n",
      "[0.818, 0.788, 0.803, 0.789, 0.803]\n",
      "average cosine accuracy for threshold 0.7\n",
      "0.8002\n",
      "average cosine fscore for threshold 0.7\n",
      "0.777878471935\n",
      "max euc acc\n",
      "[0.818, 0.788, 0.803, 0.789, 0.803]\n",
      "average euclidean accuracy for threshold 0.7\n",
      "0.8002\n",
      "average euclidean fscore for threshold 0.7\n",
      "0.777878471935\n"
     ]
    }
   ],
   "source": [
    "##inverted weights\n",
    "\n",
    "import graphlab\n",
    "        \n",
    "counter=0\n",
    "from collections import defaultdict\n",
    "max_euc_accs=[]\n",
    "max_cosine_accs=[]\n",
    "max_cosine_fscores=[]\n",
    "max_euc_fscores=[]\n",
    "eucthresholds_accs = defaultdict(list)\n",
    "eucthresholds_fscores = defaultdict(list)\n",
    "cosinethresholds_accs = defaultdict(list)\n",
    "cosinethresholds_fscores = defaultdict(list)\n",
    "\n",
    "euc_threshold_acc = defaultdict(list)\n",
    "cosine_threshold_acc = defaultdict(list)\n",
    "\n",
    "euc_threshold_fscore = defaultdict(list)\n",
    "cosine_threshold_fscore = defaultdict(list)\n",
    "for d in range(1,6):\n",
    "    i=d\n",
    "    counter+=1\n",
    "    if i==1:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions')\n",
    "    else:\n",
    "        dvdtestgl = graphlab.SFrame('dvdtestgl_random_predictions_'+str(i))\n",
    "        \n",
    "    print \"results for random dataset \"+str(d)\n",
    "    print \"euclidean distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    largestdistances=[187.1015766903101,185.2970588001871,183.7879212570837,183.48024416813925,181.01933598375618,179.46030201690846]\n",
    "    lowestdistances=[143.547901412734,165.17869111964777,167.20346886353764,175.0,176.00568172647155,176.26967975236127]\n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "\n",
    "    \n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    thresholds = [0.7]\n",
    "    euc_Fscores = []\n",
    "    euc_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        \n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    print \"euclidean distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    euc_major_Fscores=[]\n",
    "    euc_major_Accs = []\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #if thresholds[i] not in eucthresholds_accs:\n",
    "            #eucthresholds[i] =\n",
    "    print \"euclidean distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "\n",
    "    #threshold using all models\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        euc_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        euc_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print \"max euc acc\"\n",
    "    print max(euc_Accs)\n",
    "    max_euc_accs.append(max(euc_Accs))\n",
    "    max_euc_fscores.append(max(euc_Fscores))\n",
    "    \n",
    "    Minor_domains = ['automotive_predictions','jewelrywatches_predictions','gourmet_predictions','grocery_predictions','beauty_predictions','baby_predictions']\n",
    "    Major_domains = ['book_predictions','electronics_predictions','kitchen_predictions','healthpersonal_predictions','cameraphoto_predictions','apparel_predictions']\n",
    "    normalized_largestdistances = euclidean_norm_dict(largestdistances)\n",
    "    normalized_smallestdistances = euclidean_norm_dict(lowestdistances)\n",
    "    normalized_largestdistances_inverted = [0] * len(normalized_largestdistances)\n",
    "    normalized_smallestdistances_inverted = [0] * len(normalized_smallestdistances)\n",
    "    for i in range(len(normalized_largestdistances)):\n",
    "        normalized_largestdistances_inverted[i] = 1 - normalized_largestdistances[i]\n",
    "    \n",
    "    for j in range(len(normalized_smallestdistances)):\n",
    "        normalized_smallestdistances_inverted[j] = 1 - normalized_smallestdistances[j]\n",
    "    print \"Cosine distance results for the minority classifiers of random dataset \"+str(d)\n",
    "    cosine_Accs=[]\n",
    "    cosine_Fscores=[]\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_largedist(x,normalized_largestdistances,threshold) )\n",
    "        #print \"minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #print \"minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['minority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['minority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority classifiers of random dataset \"+str(d)\n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist(x,normalized_smallestdistances,threshold) )\n",
    "        #print \"majority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #print \"majority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_predictions'])\n",
    "        #cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "        #cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_predictions']))\n",
    "    \n",
    "    print \"Cosine distance results for the Majority-Minority classifiers of random dataset \"+str(d)\n",
    "    \n",
    "    \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold=thresholds[i]\n",
    "        dvdtestgl['majority_minority_predictions'] = dvdtestgl.apply(lambda x: weighted_predict_smalldist_largedistances(x,normalized_smallestdistances_inverted,normalized_largestdistances_inverted,threshold) )\n",
    "\n",
    "        #print \"majority_minority_predictions' model Fscore when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.f1_score(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        #print \"majority_minority_predictions' model Accuracy when using a threshold of \"+str(thresholds[i])\n",
    "        #print graphlab.evaluation.accuracy(kitchentestgl['label'], kitchentestgl['majority_minority_predictions'])\n",
    "        print \"max euc acc\"\n",
    "        cosine_Accs.append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_Fscores.append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_acc[threshold].append(graphlab.evaluation.accuracy(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "        cosine_threshold_fscore[threshold].append(graphlab.evaluation.f1_score(dvdtestgl['label'], dvdtestgl['majority_minority_predictions']))\n",
    "    print max(cosine_Accs)\n",
    "    max_cosine_accs.append(max(cosine_Accs))\n",
    "    max_cosine_fscores.append(max(cosine_Fscores))\n",
    "    print \"data set \"+str(counter)+' was tested!'\n",
    "print \"max cosine acc\"\n",
    "print max_cosine_accs\n",
    "max_cosine_accs_mean = sum(max_cosine_accs) / len(max_cosine_accs)\n",
    "print \"average cosine accuracy for threshold \" + str(thresholds[0])\n",
    "print max_cosine_accs_mean\n",
    "max_cosine_fscores_mean = sum(max_cosine_fscores) / len(max_cosine_fscores)\n",
    "print \"average cosine fscore for threshold \" + str(thresholds[0])\n",
    "print max_cosine_fscores_mean\n",
    "\n",
    "print \"max euc acc\"\n",
    "print max_euc_accs\n",
    "max_euc_accs_mean = sum(max_euc_accs) / len(max_euc_accs)\n",
    "\n",
    "print \"average euclidean accuracy for threshold \" + str(thresholds[0])\n",
    "print max_euc_accs_mean\n",
    "max_euc_fscores_mean = sum(max_euc_fscores) / len(max_euc_fscores)\n",
    "print \"average euclidean fscore for threshold \" + str(thresholds[0])\n",
    "print max_euc_fscores_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
