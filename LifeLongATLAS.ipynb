{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "#, header=None\n",
    "AlarmClockpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\AlarmClock.txt', sep=\"\\t\")\n",
    "#AlarmClockpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]\n",
    "#AlarmClockpd  = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\AlarmClock.txt')\n",
    "#AlarmClockgl = gl.SFrame('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\AlarmClock.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Babypd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Baby.txt', sep=\"\\t\")\n",
    "#Babypd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Bagpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Bag.txt', sep=\"\\t\")\n",
    "#Bagpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "CableModempd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\CableModem.txt', sep=\"\\t\")\n",
    "#CableModempd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Dumbbellpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Dumbbell.txt', sep=\"\\t\")\n",
    "#Dumbbellpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Flashlightpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Flashlight.txt', sep=\"\\t\")\n",
    "#Flashlightpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Glovespd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Gloves.txt', sep=\"\\t\")\n",
    "#Glovespd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "GPSpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\GPS.txt', sep=\"\\t\")\n",
    "#GPSpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "GraphicsCardpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\GraphicsCard.txt', sep=\"\\t\")\n",
    "#GraphicsCardpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Headphonepd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Headphone.txt', sep=\"\\t\")\n",
    "#Headphonepd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "HomeTheaterSystempd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\HomeTheaterSystem.txt', sep=\"\\t\")\n",
    "#HomeTheaterSystempd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Jewelrypd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Jewelry.txt', sep=\"\\t\")\n",
    "#Jewelrypd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Keyboardpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Keyboard.txt', sep=\"\\t\")\n",
    "#Keyboardpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Magazine_Subscriptionspd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Magazine_Subscriptions.txt', sep=\"\\t\")\n",
    "#Magazine_Subscriptionspd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Movies_TVpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Movies_TV.txt', sep=\"\\t\")\n",
    "#Movies_TVpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Projectorpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Projector.txt', sep=\"\\t\")\n",
    "#Projectorpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "RiceCookerpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\RiceCooker.txt', sep=\"\\t\")\n",
    "#RiceCookerpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Sandalpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Sandal.txt', sep=\"\\t\")\n",
    "#Sandalpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Vacuumpd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Vacuum.txt', sep=\"\\t\")\n",
    "#Vacuumpd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#, header=None\n",
    "Video_Gamespd = pd.read_csv('D:\\users\\omar\\Documents\\DissertationResearch\\BingLiu\\ACL2015-Chen-Datasets\\Video_Games.txt', sep=\"\\t\")\n",
    "#Video_Gamespd.columns = [\"Domain\", \"Label\", \"Rating\", \"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "    ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "    'Vacuumpd','Video_Gamespd']\n",
    "domains = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to oaabde01@louisville.edu and will expire on September 24, 2019.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Omar\\AppData\\Local\\Temp\\graphlab_server_1540604805.log.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.023987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.023987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.021987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.021987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.019988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.019988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.020989 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.020989 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.023976 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.023976 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.021986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.021986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.021988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.021988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.027982 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.027982 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.021988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.021988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.023987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.023987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.024985 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.024985 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.020999 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.020999 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.023 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.023 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.023018 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.023018 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022985 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022985 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020989 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020989 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022993 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022993 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.024986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.024986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024984 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024984 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.024004 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.024004 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.021988 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.021988 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.022986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.022986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespd.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespd.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.023987 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.023987 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AlarmClockpd.to_csv('AlarmClockpd.csv',index=False)\n",
    "AlarmClockpd = gl.SFrame('AlarmClockpd.csv')\n",
    "domains['AlarmClockpd'] = AlarmClockpd\n",
    "\n",
    "Babypd.to_csv('Babypd.csv',index=False)\n",
    "Babypd = gl.SFrame('Babypd.csv')\n",
    "domains['Babypd'] = Babypd\n",
    "\n",
    "Bagpd.to_csv('Bagpd.csv',index=False)\n",
    "Bagpd = gl.SFrame('Bagpd.csv')\n",
    "domains['Bagpd'] = Bagpd\n",
    "\n",
    "CableModempd.to_csv('CableModempd.csv',index=False)\n",
    "CableModempd = gl.SFrame('CableModempd.csv')\n",
    "domains['CableModempd'] = CableModempd\n",
    "\n",
    "Dumbbellpd.to_csv('Dumbbellpd.csv',index=False)\n",
    "Dumbbellpd = gl.SFrame('Dumbbellpd.csv')\n",
    "domains['Dumbbellpd'] = Dumbbellpd\n",
    "\n",
    "Flashlightpd.to_csv('Flashlightpd.csv',index=False)\n",
    "Flashlightpd = gl.SFrame('Flashlightpd.csv')\n",
    "domains['Flashlightpd'] = Flashlightpd\n",
    "\n",
    "Glovespd.to_csv('Glovespd.csv',index=False)\n",
    "Glovespd = gl.SFrame('Glovespd.csv')\n",
    "domains['Glovespd'] = Glovespd\n",
    "\n",
    "GPSpd.to_csv('GPSpd.csv',index=False)\n",
    "GPSpd = gl.SFrame('GPSpd.csv')\n",
    "domains['GPSpd'] = GPSpd\n",
    "\n",
    "GraphicsCardpd.to_csv('GraphicsCardpd.csv',index=False)\n",
    "GraphicsCardpd = gl.SFrame('GraphicsCardpd.csv')\n",
    "domains['GraphicsCardpd'] = GraphicsCardpd\n",
    "\n",
    "Headphonepd.to_csv('Headphonepd.csv',index=False)\n",
    "Headphonepd = gl.SFrame('Headphonepd.csv')\n",
    "domains['Headphonepd'] = Headphonepd\n",
    "\n",
    "HomeTheaterSystempd.to_csv('HomeTheaterSystempd.csv',index=False)\n",
    "HomeTheaterSystempd = gl.SFrame('HomeTheaterSystempd.csv')\n",
    "domains['HomeTheaterSystempd'] = HomeTheaterSystempd\n",
    "\n",
    "Jewelrypd.to_csv('Jewelrypd.csv',index=False)\n",
    "Jewelrypd = gl.SFrame('Jewelrypd.csv')\n",
    "domains['Jewelrypd'] = Jewelrypd\n",
    "\n",
    "Keyboardpd.to_csv('Keyboardpd.csv',index=False)\n",
    "Keyboardpd = gl.SFrame('Keyboardpd.csv')\n",
    "domains['Keyboardpd'] = Keyboardpd\n",
    "\n",
    "Magazine_Subscriptionspd.to_csv('Magazine_Subscriptionspd.csv',index=False)\n",
    "Magazine_Subscriptionspd = gl.SFrame('Magazine_Subscriptionspd.csv')\n",
    "domains['Magazine_Subscriptionspd'] = Magazine_Subscriptionspd\n",
    "\n",
    "Movies_TVpd.to_csv('Movies_TVpd.csv',index=False)\n",
    "Movies_TVpd = gl.SFrame('Movies_TVpd.csv')\n",
    "domains['Movies_TVpd'] = Movies_TVpd\n",
    "\n",
    "Projectorpd.to_csv('Projectorpd.csv',index=False)\n",
    "Projectorpd = gl.SFrame('Projectorpd.csv')\n",
    "domains['Projectorpd'] = Projectorpd\n",
    "\n",
    "RiceCookerpd.to_csv('RiceCookerpd.csv',index=False)\n",
    "RiceCookerpd = gl.SFrame('RiceCookerpd.csv')\n",
    "domains['RiceCookerpd'] = RiceCookerpd\n",
    "\n",
    "Sandalpd.to_csv('Sandalpd.csv',index=False)\n",
    "Sandalpd = gl.SFrame('Sandalpd.csv')\n",
    "domains['Sandalpd'] = Sandalpd\n",
    "\n",
    "Vacuumpd.to_csv('Vacuumpd.csv',index=False)\n",
    "Vacuumpd = gl.SFrame('Vacuumpd.csv')\n",
    "domains['Vacuumpd'] = Vacuumpd\n",
    "\n",
    "Video_Gamespd.to_csv('Video_Gamespd.csv',index=False)\n",
    "Video_Gamespd = gl.SFrame('Video_Gamespd.csv')\n",
    "domains['Video_Gamespd'] = Video_Gamespd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received kingston 256mb sd card advertised unit came mail exactly 2 days iordered worked perfectly satisfied\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#electronicsgl\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "def reviewcleaner(text):\n",
    "    #postags = ['JJ', 'JJR', 'JJS','VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','RB', 'RBR', 'RBS']\n",
    "    postags = ['JJ','VB','RB']\n",
    "    #Nountags = ['NN', 'NNP', 'NNS']\n",
    "    Nountags = ['NN']\n",
    "    #text = \"I love books in general\"\n",
    "\n",
    "    #print words\n",
    "    text = preprocess(text)\n",
    "    raw_words = text.split(\" \")\n",
    "    raw_words2 = text.split(\" \")\n",
    "    #nltk.word_tokenize(text)\n",
    "    try:\n",
    "        words = nltk.pos_tag(raw_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    newsentence=[]\n",
    "    for i in range(len(raw_words)):\n",
    "\n",
    "        #print raw_words[i]\n",
    "        #print words[i][1]\n",
    "        #print words\n",
    "        #print raw_words\n",
    "        ##if len(raw_words) != len(words):\n",
    "            ##print words\n",
    "            ##print raw_words\n",
    "            ##break\n",
    "        \n",
    "        if words[i][1] in postags:\n",
    "            newsentence.append(words[i][0])\n",
    "            continue\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.70 or hsentiments0.neg_score > 0.70:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "            ##newsentence.append(raw_words[i])\n",
    "        elif words[i][1] in Nountags:\n",
    "            #newsentence.append(words[i][0])\n",
    "            #continue\n",
    "            try:\n",
    "                sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                if len(list(sentiments))>0:\n",
    "                    hsentiments0 = list(sentiments)[0]\n",
    "                    if hsentiments0.pos_score > 0.70 or hsentiments0.neg_score > 0.70:\n",
    "                        newsentence.append(raw_words[i])\n",
    "            except:\n",
    "                continue\n",
    "    return  (str(\" \".join(newsentence)))\n",
    "\n",
    "def word_counter(textfilepath):\n",
    "    \n",
    "    \n",
    "    #'your_file.txt'\n",
    "    with open(textfilepath) as f:\n",
    "        passage = f.readlines()\n",
    "\n",
    "    words = re.findall(r'\\w+', str(passage))\n",
    "\n",
    "    cap_words = [word.upper() for word in words]\n",
    "\n",
    "    word_counts = Counter(cap_words)\n",
    "    return word_counts\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    #sentence = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    ##sentence = \" \".join(filtered_words)\n",
    "    #filtered_words = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    #filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    ##return filtered_words\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "\n",
    "#sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "sentence = \"I received my Kingston 256MB SD card just as advertised.The unit came in the mail exactly 2 days after Iordered. Worked perfectly and I'm very satisfied\"\n",
    "#sentence = \"like many\"\n",
    "print preprocess(sentence)\n",
    "text = preprocess(sentence) \n",
    "raw_words = text.split(\" \")\n",
    "words = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print len(raw_words)\n",
    "print len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received kingston 256mb sd card advertised unit came mail exactly 2 days iordered worked perfectly satisfied\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#electronicsgl\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "def reviewcleaner(text):\n",
    "    #postags = ['JJ', 'JJR', 'JJS','VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ','RB', 'RBR', 'RBS']\n",
    "    postags = ['JJ','VB','RB']\n",
    "    #Nountags = ['NN', 'NNP', 'NNS']\n",
    "    Nountags = ['NN']\n",
    "    #text = \"I love books in general\"\n",
    "\n",
    "    #print words\n",
    "    text = preprocess(text)\n",
    "    raw_words = text.split(\" \")\n",
    "    raw_words2 = text.split(\" \")\n",
    "    #nltk.word_tokenize(text)\n",
    "    try:\n",
    "        words = nltk.pos_tag(raw_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    newsentence=[]\n",
    "    for i in range(len(raw_words)):\n",
    "\n",
    "        #print raw_words[i]\n",
    "        #print words[i][1]\n",
    "        #print words\n",
    "        #print raw_words\n",
    "        ##if len(raw_words) != len(words):\n",
    "            ##print words\n",
    "            ##print raw_words\n",
    "            ##break\n",
    "        \n",
    "        if words[i][1] in postags:\n",
    "            newsentence.append(words[i][0])\n",
    "            continue\n",
    "            #try:\n",
    "                #sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                #if len(list(sentiments))>0:\n",
    "                    #hsentiments0 = list(sentiments)[0]\n",
    "                    #if hsentiments0.pos_score > 0.60 or hsentiments0.neg_score > 0.60:\n",
    "            newsentence.append(raw_words[i])\n",
    "            ##except:\n",
    "                #continue\n",
    "            ##newsentence.append(raw_words[i])\n",
    "        elif words[i][1] in Nountags:\n",
    "            #newsentence.append(words[i][0])\n",
    "            #continue\n",
    "            #try:\n",
    "                ##sentiments = swn.senti_synsets(str(raw_words[i]))\n",
    "                #if len(list(sentiments))>0:\n",
    "                    #hsentiments0 = list(sentiments)[0]\n",
    "                    #if hsentiments0.pos_score > 0.60 or hsentiments0.neg_score > 0.60:\n",
    "            newsentence.append(raw_words[i])\n",
    "            #except:\n",
    "                #continue\n",
    "    return  (str(\" \".join(newsentence)))\n",
    "\n",
    "def word_counter(textfilepath):\n",
    "    \n",
    "    \n",
    "    #'your_file.txt'\n",
    "    with open(textfilepath) as f:\n",
    "        passage = f.readlines()\n",
    "\n",
    "    words = re.findall(r'\\w+', str(passage))\n",
    "\n",
    "    cap_words = [word.upper() for word in words]\n",
    "\n",
    "    word_counts = Counter(cap_words)\n",
    "    return word_counts\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    #sentence = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    filtered_words = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    ##sentence = \" \".join(filtered_words)\n",
    "    #filtered_words = \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n",
    "    #filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    ##return filtered_words\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "\n",
    "#sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "sentence = \"I received my Kingston 256MB SD card just as advertised.The unit came in the mail exactly 2 days after Iordered. Worked perfectly and I'm very satisfied\"\n",
    "#sentence = \"like many\"\n",
    "print preprocess(sentence)\n",
    "text = preprocess(sentence)\n",
    "raw_words = text.split(\" \")\n",
    "words = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "print len(raw_words)\n",
    "print len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for d in domainnames:\n",
    "    counter+=1\n",
    "    print counter\n",
    "    domains[d]['cleanreview_nolex'] = domains[d]['Review'].apply(lambda x: reviewcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import graphlab\n",
    "counter=0\n",
    "for d in domainnames:\n",
    "    counter+=1\n",
    "    print counter\n",
    "    domains[d]['1-grams'] = graphlab.text_analytics.count_ngrams(domains[d]['Review'], 1)\n",
    "    domains[d]['2-grams'] = graphlab.text_analytics.count_ngrams(domains[d]['Review'], 2)\n",
    "    domains[d]['3-grams'] = graphlab.text_analytics.count_ngrams(domains[d]['Review'], 3)\n",
    "    domains[d]['word_count'] = gl.text_analytics.count_words(domains[d]['Review'])\n",
    "    domains[d]['tfidf'] = gl.text_analytics.tf_idf(domains[d]['word_count'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in domainnames:\n",
    "    domains[d+'posneg'] = domains[d][domains[d]['Label']!='NEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 845</pre>"
      ],
      "text/plain": [
       "Number of examples          : 845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 102373</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 102373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 102374</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 102374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001183  | 1.086374     | 1.000000          | 0.754717            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001183  | 1.086374     | 1.000000          | 0.754717            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 1.128351     | 1.000000          | 0.754717            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 1.128351     | 1.000000          | 0.754717            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 1.153334     | 1.000000          | 0.773585            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 1.153334     | 1.000000          | 0.773585            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 1.178323     | 1.000000          | 0.773585            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 1.178323     | 1.000000          | 0.773585            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 1.208303     | 1.000000          | 0.811321            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 1.208303     | 1.000000          | 0.811321            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 1.236287     | 1.000000          | 0.830189            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 1.236287     | 1.000000          | 0.830189            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 856</pre>"
      ],
      "text/plain": [
       "Number of examples          : 856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 106629</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 106629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 106630</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 106630"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001168  | 0.055986     | 0.997664          | 0.517857            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001168  | 0.055986     | 0.997664          | 0.517857            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.100943     | 1.000000          | 0.535714            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.100943     | 1.000000          | 0.535714            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.125928     | 1.000000          | 0.589286            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.125928     | 1.000000          | 0.589286            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.149914     | 1.000000          | 0.625000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.149914     | 1.000000          | 0.625000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.174899     | 1.000000          | 0.660714            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.174899     | 1.000000          | 0.660714            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.198887     | 1.000000          | 0.714286            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.198887     | 1.000000          | 0.714286            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 887</pre>"
      ],
      "text/plain": [
       "Number of examples          : 887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 115904</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 115904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 115905</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 115905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001127  | 0.062965     | 0.996618          | 0.750000            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001127  | 0.062965     | 0.996618          | 0.750000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.106941     | 1.000000          | 0.781250            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.106941     | 1.000000          | 0.781250            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.135922     | 1.000000          | 0.812500            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.135922     | 1.000000          | 0.812500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.160907     | 1.000000          | 0.875000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.160907     | 1.000000          | 0.875000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.184893     | 1.000000          | 0.875000            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.184893     | 1.000000          | 0.875000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.210879     | 1.000000          | 0.906250            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.210879     | 1.000000          | 0.906250            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.341804     | 1.000000          | 0.937500            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.341804     | 1.000000          | 0.937500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 926</pre>"
      ],
      "text/plain": [
       "Number of examples          : 926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 129561</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 129561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 129562</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 129562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001080  | 0.067964     | 0.994600          | 0.550000            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001080  | 0.067964     | 0.994600          | 0.550000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.113934     | 1.000000          | 0.575000            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.113934     | 1.000000          | 0.575000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.142919     | 1.000000          | 0.675000            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.142919     | 1.000000          | 0.675000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.170904     | 1.000000          | 0.675000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.170904     | 1.000000          | 0.675000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.201884     | 1.000000          | 0.750000            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.201884     | 1.000000          | 0.750000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.231866     | 1.000000          | 0.800000            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.231866     | 1.000000          | 0.800000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.382779     | 1.000000          | 0.875000            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.382779     | 1.000000          | 0.875000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 873</pre>"
      ],
      "text/plain": [
       "Number of examples          : 873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 117702</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 117702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 117703</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 117703"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001145  | 0.061966     | 1.000000          | 0.810811            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001145  | 0.061966     | 1.000000          | 0.810811            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.106938     | 1.000000          | 0.810811            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.106938     | 1.000000          | 0.810811            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.133923     | 1.000000          | 0.837838            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.133923     | 1.000000          | 0.837838            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.162906     | 1.000000          | 0.837838            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.162906     | 1.000000          | 0.837838            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.187894     | 1.000000          | 0.891892            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.187894     | 1.000000          | 0.891892            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.214876     | 1.000000          | 0.891892            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.214876     | 1.000000          | 0.891892            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 881</pre>"
      ],
      "text/plain": [
       "Number of examples          : 881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 117133</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 117133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 117134</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 117134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001135  | 0.061969     | 0.994325          | 0.651163            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001135  | 0.061969     | 0.994325          | 0.651163            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.102942     | 1.000000          | 0.674419            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.102942     | 1.000000          | 0.674419            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.127927     | 1.000000          | 0.790698            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.127927     | 1.000000          | 0.790698            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.153911     | 1.000000          | 0.813953            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.153911     | 1.000000          | 0.813953            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.177897     | 1.000000          | 0.813953            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.177897     | 1.000000          | 0.813953            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.202884     | 1.000000          | 0.837209            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.202884     | 1.000000          | 0.837209            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.333809     | 1.000000          | 0.953488            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.333809     | 1.000000          | 0.953488            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 880</pre>"
      ],
      "text/plain": [
       "Number of examples          : 880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 88504</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 88504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 88505</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 88505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001136  | 0.054970     | 0.995455          | 0.604651            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001136  | 0.054970     | 0.995455          | 0.604651            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.099944     | 1.000000          | 0.651163            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.099944     | 1.000000          | 0.651163            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.128925     | 1.000000          | 0.767442            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.128925     | 1.000000          | 0.767442            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.153911     | 1.000000          | 0.790698            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.153911     | 1.000000          | 0.790698            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.180896     | 1.000000          | 0.813953            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.180896     | 1.000000          | 0.813953            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.205881     | 1.000000          | 0.837209            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.205881     | 1.000000          | 0.837209            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.352798     | 1.000000          | 0.976744            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.352798     | 1.000000          | 0.976744            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 867</pre>"
      ],
      "text/plain": [
       "Number of examples          : 867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 160692</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 160692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 160693</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 160693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001153  | 0.096942     | 0.997693          | 0.588235            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001153  | 0.096942     | 0.997693          | 0.588235            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.166905     | 1.000000          | 0.607843            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.166905     | 1.000000          | 0.607843            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.205879     | 1.000000          | 0.627451            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.205879     | 1.000000          | 0.627451            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.242859     | 1.000000          | 0.666667            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.242859     | 1.000000          | 0.666667            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.285834     | 1.000000          | 0.686275            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.285834     | 1.000000          | 0.686275            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.325810     | 1.000000          | 0.705882            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.325810     | 1.000000          | 0.705882            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 875</pre>"
      ],
      "text/plain": [
       "Number of examples          : 875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 175336</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 175336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 175337</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 175337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001143  | 0.127928     | 0.997714          | 0.775862            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001143  | 0.127928     | 0.997714          | 0.775862            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.212878     | 1.000000          | 0.775862            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.212878     | 1.000000          | 0.775862            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.255853     | 1.000000          | 0.775862            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.255853     | 1.000000          | 0.775862            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.309822     | 1.000000          | 0.793103            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.309822     | 1.000000          | 0.793103            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.358795     | 1.000000          | 0.844828            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.358795     | 1.000000          | 0.844828            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.410766     | 1.000000          | 0.879310            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.410766     | 1.000000          | 0.879310            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 849</pre>"
      ],
      "text/plain": [
       "Number of examples          : 849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 143829</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 143829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 143830</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 143830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001178  | 0.082954     | 1.000000          | 0.761905            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001178  | 0.082954     | 1.000000          | 0.761905            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.144917     | 1.000000          | 0.761905            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.144917     | 1.000000          | 0.761905            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.177898     | 1.000000          | 0.785714            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.177898     | 1.000000          | 0.785714            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.210880     | 1.000000          | 0.785714            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.210880     | 1.000000          | 0.785714            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.243861     | 1.000000          | 0.809524            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.243861     | 1.000000          | 0.809524            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.280840     | 1.000000          | 0.833333            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.280840     | 1.000000          | 0.833333            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 865</pre>"
      ],
      "text/plain": [
       "Number of examples          : 865"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 170707</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 170707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 170708</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 170708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001156  | 0.097945     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001156  | 0.097945     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.166905     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.166905     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.207881     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.207881     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.251856     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.251856     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.296830     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.296830     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.339805     | 1.000000          | 0.950000            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.339805     | 1.000000          | 0.950000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 855</pre>"
      ],
      "text/plain": [
       "Number of examples          : 855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 61166</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 61166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 61167</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 61167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001170  | 0.035982     | 0.991813          | 0.652174            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001170  | 0.035982     | 0.991813          | 0.652174            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.064964     | 1.000000          | 0.782609            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.064964     | 1.000000          | 0.782609            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.081956     | 1.000000          | 0.847826            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.081956     | 1.000000          | 0.847826            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.100944     | 1.000000          | 0.891304            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.100944     | 1.000000          | 0.891304            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.117934     | 1.000000          | 0.913043            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.117934     | 1.000000          | 0.913043            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.135925     | 1.000000          | 0.913043            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.135925     | 1.000000          | 0.913043            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.228869     | 1.000000          | 0.869565            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.228869     | 1.000000          | 0.869565            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 844</pre>"
      ],
      "text/plain": [
       "Number of examples          : 844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 144106</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 144106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 144107</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 144107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001185  | 0.084940     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001185  | 0.084940     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.136910     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.136910     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.169891     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.169891     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.202872     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.202872     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.234854     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.234854     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.268835     | 1.000000          | 0.846154            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.268835     | 1.000000          | 0.846154            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 876</pre>"
      ],
      "text/plain": [
       "Number of examples          : 876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 121688</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 121688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 121689</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 121689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001142  | 0.074959     | 0.995434          | 0.697674            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001142  | 0.074959     | 0.995434          | 0.697674            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.138921     | 1.000000          | 0.720930            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.138921     | 1.000000          | 0.720930            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.178899     | 1.000000          | 0.744186            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.178899     | 1.000000          | 0.744186            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.215877     | 1.000000          | 0.790698            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.215877     | 1.000000          | 0.790698            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.256854     | 1.000000          | 0.790698            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.256854     | 1.000000          | 0.790698            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.299829     | 1.000000          | 0.790698            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.299829     | 1.000000          | 0.790698            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 881</pre>"
      ],
      "text/plain": [
       "Number of examples          : 881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 163032</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 163032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 163033</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 163033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001135  | 0.097943     | 0.997730          | 0.775510            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001135  | 0.097943     | 0.997730          | 0.775510            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.164905     | 1.000000          | 0.816327            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.164905     | 1.000000          | 0.816327            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.199886     | 1.000000          | 0.816327            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.199886     | 1.000000          | 0.816327            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.235864     | 1.000000          | 0.836735            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.235864     | 1.000000          | 0.836735            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.272843     | 1.000000          | 0.877551            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.272843     | 1.000000          | 0.877551            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.313819     | 1.000000          | 0.897959            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.313819     | 1.000000          | 0.897959            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.510707     | 1.000000          | 0.938776            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.510707     | 1.000000          | 0.938776            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 871</pre>"
      ],
      "text/plain": [
       "Number of examples          : 871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 180030</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 180030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 180031</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 180031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001148  | 0.111935     | 0.998852          | 0.916667            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001148  | 0.111935     | 0.998852          | 0.916667            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 9        | 1.189593  | 0.287835     | 1.000000          | 0.937500            |</pre>"
      ],
      "text/plain": [
       "| 2         | 9        | 1.189593  | 0.287835     | 1.000000          | 0.937500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 10       | 1.189593  | 0.333808     | 1.000000          | 0.937500            |</pre>"
      ],
      "text/plain": [
       "| 3         | 10       | 1.189593  | 0.333808     | 1.000000          | 0.937500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 11       | 1.189593  | 0.380780     | 1.000000          | 0.937500            |</pre>"
      ],
      "text/plain": [
       "| 4         | 11       | 1.189593  | 0.380780     | 1.000000          | 0.937500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 12       | 1.189593  | 0.431751     | 1.000000          | 0.937500            |</pre>"
      ],
      "text/plain": [
       "| 5         | 12       | 1.189593  | 0.431751     | 1.000000          | 0.937500            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 13       | 1.189593  | 0.478725     | 1.000000          | 0.916667            |</pre>"
      ],
      "text/plain": [
       "| 6         | 13       | 1.189593  | 0.478725     | 1.000000          | 0.916667            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 895</pre>"
      ],
      "text/plain": [
       "Number of examples          : 895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 112640</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 112640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 112641</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 112641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001117  | 0.053969     | 1.000000          | 0.931818            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001117  | 0.053969     | 1.000000          | 0.931818            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.092946     | 1.000000          | 0.931818            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.092946     | 1.000000          | 0.931818            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.114933     | 1.000000          | 0.931818            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.114933     | 1.000000          | 0.931818            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.137920     | 1.000000          | 0.954545            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.137920     | 1.000000          | 0.954545            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.160907     | 1.000000          | 0.954545            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.160907     | 1.000000          | 0.954545            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.185892     | 1.000000          | 0.954545            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.185892     | 1.000000          | 0.954545            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.300826     | 1.000000          | 0.931818            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.300826     | 1.000000          | 0.931818            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 899</pre>"
      ],
      "text/plain": [
       "Number of examples          : 899"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 88749</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 88749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 88750</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 88750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001112  | 0.050972     | 0.993326          | 0.666667            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001112  | 0.050972     | 0.993326          | 0.666667            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.091946     | 1.000000          | 0.764706            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.091946     | 1.000000          | 0.764706            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.130923     | 1.000000          | 0.823529            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.130923     | 1.000000          | 0.823529            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.157908     | 1.000000          | 0.862745            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.157908     | 1.000000          | 0.862745            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.184893     | 1.000000          | 0.921569            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.184893     | 1.000000          | 0.921569            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.212876     | 1.000000          | 0.941176            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.212876     | 1.000000          | 0.941176            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.345802     | 1.000000          | 0.901961            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.345802     | 1.000000          | 0.901961            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 875</pre>"
      ],
      "text/plain": [
       "Number of examples          : 875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 140508</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 140508"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 140509</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 140509"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001143  | 0.082955     | 1.000000          | 0.911111            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001143  | 0.082955     | 1.000000          | 0.911111            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.140921     | 1.000000          | 0.911111            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.140921     | 1.000000          | 0.911111            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.175900     | 1.000000          | 0.911111            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.175900     | 1.000000          | 0.911111            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.215879     | 1.000000          | 0.888889            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.215879     | 1.000000          | 0.888889            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.253858     | 1.000000          | 0.888889            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.253858     | 1.000000          | 0.888889            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.294834     | 1.000000          | 0.888889            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.294834     | 1.000000          | 0.888889            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 874</pre>"
      ],
      "text/plain": [
       "Number of examples          : 874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 5</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 198988</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 198988"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 198989</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 198989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.001144  | 0.117933     | 1.000000          | 0.617647            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.001144  | 0.117933     | 1.000000          | 0.617647            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.206883     | 1.000000          | 0.617647            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.206883     | 1.000000          | 0.617647            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.257852     | 1.000000          | 0.647059            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.257852     | 1.000000          | 0.647059            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.316819     | 1.000000          | 0.676471            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.316819     | 1.000000          | 0.676471            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.366790     | 1.000000          | 0.705882            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.366790     | 1.000000          | 0.705882            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.417760     | 1.000000          | 0.764706            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.417760     | 1.000000          | 0.764706            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 11        | 14       | 1.000000  | 0.693602     | 1.000000          | 0.852941            |</pre>"
      ],
      "text/plain": [
       "| 11        | 14       | 1.000000  | 0.693602     | 1.000000          | 0.852941            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphlab\n",
    "#,'d2v_400' 'w2v_400'\n",
    "featureset1=['1-grams','2-grams','3-grams','word_count','tfidf']\n",
    "domainclassifiers={}\n",
    "for d in domainnames:    \n",
    "    domainclassifiers[d] = graphlab.classifier.logistic_classifier.create(domains[d+'posneg'],target='Label',features=featureset1,max_iterations=300,class_weights='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "    ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "    'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "import graphlab\n",
    "counter=0\n",
    "for d in domainnames:\n",
    "    for j in domainnames:\n",
    "        if d!=j:\n",
    "            domains[d][j+'_prediction'] = domainclassifiers[j].predict(domains[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_counter_bysample(text):\n",
    "    \n",
    "    \n",
    "    #'your_file.txt'\n",
    "    #with open(textfilepath) as f:\n",
    "        #passage = f.readlines()\n",
    "\n",
    "    words = re.findall(r'\\w+', str(text))\n",
    "\n",
    "    cap_words = [word.upper() for word in words]\n",
    "\n",
    "    word_counts = Counter(cap_words)\n",
    "    return word_counts\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "def euclidean_norm_dict(vec):\n",
    "    vector=[]\n",
    "    #for v in vec:\n",
    "        #vector.append(v)\n",
    "    enorm = LA.norm(vec)\n",
    "    #for i in vec:\n",
    "        #vec[i] = float(vec[i]/enorm)\n",
    "    return vec / enorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_lifelong_inverted_distance(sframe,targetdomainname,threshold,topk,euc):\n",
    "    score=0\n",
    "    distances={}\n",
    "    euclidean_distances= defaultdict(dict)\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    distances[targetdomainname] = word_counter_bysample(sframe['cleanreview_nolex'])\n",
    "    #for d in domainnames:\n",
    "    for j in domainnames:\n",
    "        if targetdomainname!=j:\n",
    "            distances[j] = word_counter(j+'cleanreviewnolex_sentimentscore07forall.csv')\n",
    "            cosine_distances[targetdomainname][j] = gl.distances.cosine(distances[targetdomainname],distances[j])\n",
    "    for j in domainnames:\n",
    "        if targetdomainname!=j:\n",
    "            distances[j] = word_counter(j+'cleanreviewnolex_sentimentscore07forall.csv')\n",
    "            euclidean_distances[targetdomainname][j] = gl.distances.euclidean(distances[targetdomainname],distances[j])\n",
    "    #for d in domainnames:\n",
    "    if euc:\n",
    "        distances={}\n",
    "        for j in domainnames:\n",
    "            if targetdomainname!=j:\n",
    "                distances[j] = euclidean_distances[targetdomainname][j]\n",
    "        sorted_distances = sorted(distances.iterkeys())\n",
    "        classifiers=[]\n",
    "        weights=[]\n",
    "        for k in sorted_distances:\n",
    "            classifiers.append(k)\n",
    "            weights.append(distances[k])\n",
    "        normalized_weights = euclidean_norm_dict(weights)\n",
    "    else:\n",
    "        distances={}\n",
    "        for j in domainnames:\n",
    "            if targetdomainname!=j:\n",
    "                distances[j] = cosine_distances[targetdomainname][j]\n",
    "        sorted_distances = sorted(distances.iterkeys())\n",
    "        classifiers=[]\n",
    "        weights=[]\n",
    "        for k in sorted_distances:\n",
    "            classifiers.append(k)\n",
    "            weights.append(distances[k])\n",
    "        normalized_weights = euclidean_norm_dict(weights)\n",
    "    normalized_weights_inverted=[0]*len(normalized_weights)\n",
    "    for i in range(len(normalized_weights)):\n",
    "        normalized_weights_inverted[i] = 1 - normalized_weights[i] \n",
    "            ####################\n",
    "    for i in range(len(classifiers)):\n",
    "        \n",
    "        if sframe[classifiers[i]+'_prediction']=='POS':\n",
    "            score+=normalized_weights_inverted[i]\n",
    "        elif sframe[classifiers[i]+'_prediction']=='NEG':\n",
    "            score+=0\n",
    "        if i>topk:\n",
    "            break\n",
    "    if score> sum(normalized_weights_inverted) * threshold:\n",
    "        return 'POS'\n",
    "    else:\n",
    "        return 'NEG'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "    ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "    'Vacuumpd','Video_Gamespd']\n",
    "negativedistr={}\n",
    "\n",
    "negativedistr['AlarmClockpd'] = 30.51\n",
    "negativedistr['Babypd'] = 16.45\n",
    "negativedistr['Bagpd'] = 11.97\n",
    "negativedistr['CableModempd'] = 12.53\n",
    "negativedistr['Dumbbellpd'] = 16.04\n",
    "negativedistr['Flashlightpd'] = 11.69\n",
    "negativedistr['Glovespd'] = 13.76\n",
    "negativedistr['GPSpd'] = 19.50\n",
    "negativedistr['GraphicsCardpd'] = 14.58\n",
    "negativedistr['Headphonepd'] = 20.99\n",
    "negativedistr['HomeTheaterSystempd'] = 28.84\n",
    "negativedistr['Jewelrypd'] = 12.21\n",
    "negativedistr['Keyboardpd'] = 22.66\n",
    "negativedistr['Magazine_Subscriptionspd'] = 26.88\n",
    "negativedistr['Movies_TVpd'] = 10.86\n",
    "negativedistr['Projectorpd'] = 20.24\n",
    "negativedistr['RiceCookerpd'] = 18.64\n",
    "negativedistr['Sandalpd'] = 12.11\n",
    "negativedistr['Vacuumpd'] = 22.07\n",
    "negativedistr['Video_Gamespd'] = 20.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.111933 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.111933 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 898 lines in 0.15193 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 898 lines in 0.15193 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.104939 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.104939 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 912 lines in 0.078953 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 912 lines in 0.078953 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.115933 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.115933 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.155911 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.155911 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.138919 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.138919 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 966 lines in 0.168902 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 966 lines in 0.168902 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.116934 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.116934 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 910 lines in 0.163896 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 910 lines in 0.163896 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.121929 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.121929 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 924 lines in 0.176882 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 924 lines in 0.176882 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.095944 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.095944 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 923 lines in 0.125927 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 923 lines in 0.125927 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.15291 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.15291 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 918 lines in 0.20788 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 918 lines in 0.20788 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.165904 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.165904 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 933 lines in 0.203899 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 933 lines in 0.203899 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.164906 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.164906 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 891 lines in 0.212879 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 891 lines in 0.212879 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.162906 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.162906 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 905 lines in 0.218891 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 905 lines in 0.218891 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.075957 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.075957 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 901 lines in 0.102949 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 901 lines in 0.102949 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.142916 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.142916 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 896 lines in 0.18691 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 896 lines in 0.18691 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.117919 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.117919 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.166904 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.166904 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.1729 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.1729 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 930 lines in 0.215876 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 930 lines in 0.215876 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.175899 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.175899 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.216887 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.216887 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.118932 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.118932 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 939 lines in 0.167917 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 939 lines in 0.167917 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.098942 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.098942 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 950 lines in 0.134923 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 950 lines in 0.134923 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.141918 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.141918 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 920 lines in 0.217876 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 920 lines in 0.217876 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.210878 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.210878 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 908 lines in 0.254863 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 908 lines in 0.254863 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore of the aggregation on the AlarmClockpd domain\n",
      "0.805555555556\n",
      "Accuracy of the aggregation on the AlarmClockpd domain\n",
      "0.890868596882\n",
      "Fscore of the aggregation on the Babypd domain\n",
      "0.705035971223\n",
      "Accuracy of the aggregation on the Babypd domain\n",
      "0.910087719298\n",
      "Fscore of the aggregation on the Bagpd domain\n",
      "0.68932038835\n",
      "Accuracy of the aggregation on the Bagpd domain\n",
      "0.930359085963\n",
      "Fscore of the aggregation on the CableModempd domain\n",
      "0.549763033175\n",
      "Accuracy of the aggregation on the CableModempd domain\n",
      "0.8033126294\n",
      "Fscore of the aggregation on the Dumbbellpd domain\n",
      "0.699386503067\n",
      "Accuracy of the aggregation on the Dumbbellpd domain\n",
      "0.892307692308\n",
      "Fscore of the aggregation on the Flashlightpd domain\n",
      "0.60162601626\n",
      "Accuracy of the aggregation on the Flashlightpd domain\n",
      "0.893939393939\n",
      "Fscore of the aggregation on the Glovespd domain\n",
      "0.677165354331\n",
      "Accuracy of the aggregation on the Glovespd domain\n",
      "0.911159263272\n",
      "Fscore of the aggregation on the GPSpd domain\n",
      "0.780104712042\n",
      "Accuracy of the aggregation on the GPSpd domain\n",
      "0.908496732026\n",
      "Fscore of the aggregation on the GraphicsCardpd domain\n",
      "0.69970845481\n",
      "Accuracy of the aggregation on the GraphicsCardpd domain\n",
      "0.889603429796\n",
      "Fscore of the aggregation on the Headphonepd domain\n",
      "0.737704918033\n",
      "Accuracy of the aggregation on the Headphonepd domain\n",
      "0.892255892256\n",
      "Fscore of the aggregation on the HomeTheaterSystempd domain\n",
      "0.841897233202\n",
      "Accuracy of the aggregation on the HomeTheaterSystempd domain\n",
      "0.911602209945\n",
      "Fscore of the aggregation on the Jewelrypd domain\n",
      "0.691666666667\n",
      "Accuracy of the aggregation on the Jewelrypd domain\n",
      "0.917869034406\n",
      "Fscore of the aggregation on the Keyboardpd domain\n",
      "0.785529715762\n",
      "Accuracy of the aggregation on the Keyboardpd domain\n",
      "0.907366071429\n",
      "Fscore of the aggregation on the Magazine_Subscriptionspd domain\n",
      "0.731601731602\n",
      "Accuracy of the aggregation on the Magazine_Subscriptionspd domain\n",
      "0.865070729053\n",
      "Fscore of the aggregation on the Movies_TVpd domain\n",
      "0.6\n",
      "Accuracy of the aggregation on the Movies_TVpd domain\n",
      "0.905376344086\n",
      "Fscore of the aggregation on the Projectorpd domain\n",
      "0.832\n",
      "Accuracy of the aggregation on the Projectorpd domain\n",
      "0.931447225245\n",
      "Fscore of the aggregation on the RiceCookerpd domain\n",
      "0.773109243697\n",
      "Accuracy of the aggregation on the RiceCookerpd domain\n",
      "0.913738019169\n",
      "Fscore of the aggregation on the Sandalpd domain\n",
      "0.621722846442\n",
      "Accuracy of the aggregation on the Sandalpd domain\n",
      "0.893684210526\n",
      "Fscore of the aggregation on the Vacuumpd domain\n",
      "0.853470437018\n",
      "Accuracy of the aggregation on the Vacuumpd domain\n",
      "0.938043478261\n",
      "Fscore of the aggregation on the Video_Gamespd domain\n",
      "0.737704918033\n",
      "Accuracy of the aggregation on the Video_Gamespd domain\n",
      "0.894273127753\n",
      "test set 0 is processed\n",
      "[0.7207036849634716]\n",
      "[0.9000430442506872]\n",
      "[0.7207036849634716]\n",
      "[0.9000430442506872]\n"
     ]
    }
   ],
   "source": [
    "##inverted distance\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "for j in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "        negsamples=domains[d][domains[d]['Label']=='NEG']\n",
    "        possamples = domains[d][domains[d]['Label']=='POS']\n",
    "        negativedistr[d] = float(len(negsamples)) / float(len(possamples)) * 100\n",
    "        negsamplessize = float(len(possamples))  * negativedistr[d] / 100\n",
    "        newnegativesamplesizes[d] = int(negsamplessize)\n",
    "\n",
    "        domains[d+'posneg_bl'] = possamples\n",
    "        proportion= float(newnegativesamplesizes[d]) / float(len(negsamples))\n",
    "        initial=True\n",
    "        while initial:  \n",
    "            random_negsamples = negsamples.sample(proportion)\n",
    "            if len(random_negsamples)>= newnegativesamplesizes[d]:\n",
    "                reducednegativesamples = random_negsamples[:newnegativesamplesizes[d]]\n",
    "                initial=False\n",
    "        #domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(negsamples[:newnegativesamplesizes[d]])\n",
    "        domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(reducednegativesamples)\n",
    "        \n",
    "        #print \"Negative Samples\"\n",
    "        #print actualnegativedistr[d]\n",
    "        #print \"new negative sample sizes\"\n",
    "        #print newnegativesamplesizes[d]\n",
    "        #print \"Positive Samples\"\n",
    "        #print len(possamples)\n",
    "        #print len(domains[d+'posneg'])\n",
    "        #print len(domains[d+'posneg_bl'])\n",
    "        #print len(reducednegativesamples)\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    for d in domainnames:\n",
    "        counter+=1\n",
    "        print counter\n",
    "        #domains[d+'posneg_bl']['1-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 1)\n",
    "        #domains[d+'posneg_bl']['2-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 2)\n",
    "        #domains[d+'posneg_bl']['3-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 3)\n",
    "        #domains[d+'posneg_bl']['word_count'] = gl.text_analytics.count_words(domains[d+'posneg_bl']['Review'])\n",
    "        #domains[d+'posneg_bl']['tfidf'] = gl.text_analytics.tf_idf(domains[d+'posneg_bl']['word_count'])\n",
    "        domains[d+'posneg_bl'].save(d+'posneg_bl_wordnet.csv')\n",
    "    \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "        #0.5 then topk=21 cosine\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl'] = gl.SFrame(d+'posneg_bl_wordnet.csv')\n",
    "        for d in domainnames:\n",
    "            euc = False\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "        def flip(label):\n",
    "            if label=='NEG':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "            #domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            #domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "            print Acc\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print \"test set \"+str(j)+\" is processed\"\n",
    "    print Fscore_avgs\n",
    "    print Acc_avgs\n",
    "print Fscore_avgs\n",
    "print Acc_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.146915 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.146915 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 898 lines in 0.163903 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 898 lines in 0.163903 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.115932 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.115932 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 912 lines in 0.149895 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 912 lines in 0.149895 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.125928 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.125928 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.161906 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.161906 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.137919 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.137919 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 966 lines in 0.22887 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 966 lines in 0.22887 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.132923 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.132923 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 910 lines in 0.167903 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 910 lines in 0.167903 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.129925 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.129925 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 924 lines in 0.182895 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 924 lines in 0.182895 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.096943 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.096943 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 923 lines in 0.146914 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 923 lines in 0.146914 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.159908 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.159908 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 918 lines in 0.252854 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 918 lines in 0.252854 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.194888 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.194888 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 933 lines in 0.248858 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 933 lines in 0.248858 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.161895 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.161895 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 891 lines in 0.220873 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 891 lines in 0.220873 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.201884 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.201884 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 905 lines in 0.253854 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 905 lines in 0.253854 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.090947 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.090947 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 901 lines in 0.10394 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 901 lines in 0.10394 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.151912 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.151912 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 896 lines in 0.2039 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 896 lines in 0.2039 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.120931 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.120931 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.175898 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.175898 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.177888 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.177888 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 930 lines in 0.238863 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 930 lines in 0.238863 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.188888 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.188888 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.246848 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.246848 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.143898 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.143898 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 939 lines in 0.186893 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 939 lines in 0.186893 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.114934 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.114934 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 950 lines in 0.149914 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 950 lines in 0.149914 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.175898 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.175898 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 920 lines in 0.237864 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 920 lines in 0.237864 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.253853 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.253853 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 908 lines in 0.284849 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 908 lines in 0.284849 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscore of the aggregation on the AlarmClockpd domain\n",
      "0.800788954635\n",
      "Accuracy of the aggregation on the AlarmClockpd domain\n",
      "0.887527839644\n",
      "Fscore of the aggregation on the Babypd domain\n",
      "0.726618705036\n",
      "Accuracy of the aggregation on the Babypd domain\n",
      "0.916666666667\n",
      "Fscore of the aggregation on the Bagpd domain\n",
      "0.686274509804\n",
      "Accuracy of the aggregation on the Bagpd domain\n",
      "0.930359085963\n",
      "Fscore of the aggregation on the CableModempd domain\n",
      "0.564476885645\n",
      "Accuracy of the aggregation on the CableModempd domain\n",
      "0.814699792961\n",
      "Fscore of the aggregation on the Dumbbellpd domain\n",
      "0.715654952077\n",
      "Accuracy of the aggregation on the Dumbbellpd domain\n",
      "0.902197802198\n",
      "Fscore of the aggregation on the Flashlightpd domain\n",
      "0.615384615385\n",
      "Accuracy of the aggregation on the Flashlightpd domain\n",
      "0.897186147186\n",
      "Fscore of the aggregation on the Glovespd domain\n",
      "0.66935483871\n",
      "Accuracy of the aggregation on the Glovespd domain\n",
      "0.911159263272\n",
      "Fscore of the aggregation on the GPSpd domain\n",
      "0.763925729443\n",
      "Accuracy of the aggregation on the GPSpd domain\n",
      "0.903050108932\n",
      "Fscore of the aggregation on the GraphicsCardpd domain\n",
      "0.684057971014\n",
      "Accuracy of the aggregation on the GraphicsCardpd domain\n",
      "0.883172561629\n",
      "Fscore of the aggregation on the Headphonepd domain\n",
      "0.739726027397\n",
      "Accuracy of the aggregation on the Headphonepd domain\n",
      "0.893378226712\n",
      "Fscore of the aggregation on the HomeTheaterSystempd domain\n",
      "0.838966202783\n",
      "Accuracy of the aggregation on the HomeTheaterSystempd domain\n",
      "0.910497237569\n",
      "Fscore of the aggregation on the Jewelrypd domain\n",
      "0.697095435685\n",
      "Accuracy of the aggregation on the Jewelrypd domain\n",
      "0.91897891232\n",
      "Fscore of the aggregation on the Keyboardpd domain\n",
      "0.802083333333\n",
      "Accuracy of the aggregation on the Keyboardpd domain\n",
      "0.915178571429\n",
      "Fscore of the aggregation on the Magazine_Subscriptionspd domain\n",
      "0.736383442266\n",
      "Accuracy of the aggregation on the Magazine_Subscriptionspd domain\n",
      "0.868335146899\n",
      "Fscore of the aggregation on the Movies_TVpd domain\n",
      "0.641860465116\n",
      "Accuracy of the aggregation on the Movies_TVpd domain\n",
      "0.917204301075\n",
      "Fscore of the aggregation on the Projectorpd domain\n",
      "0.819843342037\n",
      "Accuracy of the aggregation on the Projectorpd domain\n",
      "0.924918389554\n",
      "Fscore of the aggregation on the RiceCookerpd domain\n",
      "0.77094972067\n",
      "Accuracy of the aggregation on the RiceCookerpd domain\n",
      "0.912673056443\n",
      "Fscore of the aggregation on the Sandalpd domain\n",
      "0.646840148699\n",
      "Accuracy of the aggregation on the Sandalpd domain\n",
      "0.9\n",
      "Fscore of the aggregation on the Vacuumpd domain\n",
      "0.855696202532\n",
      "Accuracy of the aggregation on the Vacuumpd domain\n",
      "0.938043478261\n",
      "Fscore of the aggregation on the Video_Gamespd domain\n",
      "0.735376044568\n",
      "Accuracy of the aggregation on the Video_Gamespd domain\n",
      "0.895374449339\n",
      "test set 0 is processed\n",
      "[0.7255678763417269]\n",
      "[0.9020300519025681]\n",
      "[0.7255678763417269]\n",
      "[0.9020300519025681]\n"
     ]
    }
   ],
   "source": [
    "##inverted distance\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "for j in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "        negsamples=domains[d][domains[d]['Label']=='NEG']\n",
    "        possamples = domains[d][domains[d]['Label']=='POS']\n",
    "        negativedistr[d] = float(len(negsamples)) / float(len(possamples)) * 100\n",
    "        negsamplessize = float(len(possamples))  * negativedistr[d] / 100\n",
    "        newnegativesamplesizes[d] = int(negsamplessize)\n",
    "\n",
    "        domains[d+'posneg_bl'] = possamples\n",
    "        proportion= float(newnegativesamplesizes[d]) / float(len(negsamples))\n",
    "        initial=True\n",
    "        while initial:  \n",
    "            random_negsamples = negsamples.sample(proportion)\n",
    "            if len(random_negsamples)>= newnegativesamplesizes[d]:\n",
    "                reducednegativesamples = random_negsamples[:newnegativesamplesizes[d]]\n",
    "                initial=False\n",
    "        #domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(negsamples[:newnegativesamplesizes[d]])\n",
    "        domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(reducednegativesamples)\n",
    "        \n",
    "        #print \"Negative Samples\"\n",
    "        #print actualnegativedistr[d]\n",
    "        #print \"new negative sample sizes\"\n",
    "        #print newnegativesamplesizes[d]\n",
    "        #print \"Positive Samples\"\n",
    "        #print len(possamples)\n",
    "        #print len(domains[d+'posneg'])\n",
    "        #print len(domains[d+'posneg_bl'])\n",
    "        #print len(reducednegativesamples)\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    for d in domainnames:\n",
    "        counter+=1\n",
    "        print counter\n",
    "        #domains[d+'posneg_bl']['1-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 1)\n",
    "        #domains[d+'posneg_bl']['2-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 2)\n",
    "        #domains[d+'posneg_bl']['3-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 3)\n",
    "        #domains[d+'posneg_bl']['word_count'] = gl.text_analytics.count_words(domains[d+'posneg_bl']['Review'])\n",
    "        #domains[d+'posneg_bl']['tfidf'] = gl.text_analytics.tf_idf(domains[d+'posneg_bl']['word_count'])\n",
    "        domains[d+'posneg_bl'].save(d+'posneg_bl_wordnet.csv')\n",
    "    \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "        #0.5 then topk=21 cosine\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl'] = gl.SFrame(d+'posneg_bl_wordnet.csv')\n",
    "        for d in domainnames:\n",
    "            euc = True\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "        def flip(label):\n",
    "            if label=='NEG':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "            #domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            #domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "            print Acc\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print \"test set \"+str(j)+\" is processed\"\n",
    "    print Fscore_avgs\n",
    "    print Acc_avgs\n",
    "print Fscore_avgs\n",
    "print Acc_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classify_lifelong_inverted_distance(sframe,targetdomainname,threshold,topk,euc):\n",
    "    score=0\n",
    "    distances={}\n",
    "    euclidean_distances= defaultdict(dict)\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    distances[targetdomainname] = word_counter_bysample(sframe['cleanreview_nolex'])\n",
    "    #for d in domainnames:\n",
    "    for j in domainnames:\n",
    "        if targetdomainname!=j:\n",
    "            #cleanreviewnolex_nosentimentscoreforall.csv\n",
    "            distances[j] = word_counter(j+'cleanreviewnolex_nosentimentscoreforall.csv')\n",
    "            cosine_distances[targetdomainname][j] = gl.distances.cosine(distances[targetdomainname],distances[j])\n",
    "    for j in domainnames:\n",
    "        if targetdomainname!=j:\n",
    "            distances[j] = word_counter(j+'cleanreviewnolex_nosentimentscoreforall.csv')\n",
    "            euclidean_distances[targetdomainname][j] = gl.distances.euclidean(distances[targetdomainname],distances[j])\n",
    "    #for d in domainnames:\n",
    "    if euc:\n",
    "        distances={}\n",
    "        for j in domainnames:\n",
    "            if targetdomainname!=j:\n",
    "                distances[j] = euclidean_distances[targetdomainname][j]\n",
    "        sorted_distances = sorted(distances.iterkeys())\n",
    "        classifiers=[]\n",
    "        weights=[]\n",
    "        for k in sorted_distances:\n",
    "            classifiers.append(k)\n",
    "            weights.append(distances[k])\n",
    "        normalized_weights = euclidean_norm_dict(weights)\n",
    "    else:\n",
    "        distances={}\n",
    "        for j in domainnames:\n",
    "            if targetdomainname!=j:\n",
    "                distances[j] = cosine_distances[targetdomainname][j]\n",
    "        sorted_distances = sorted(distances.iterkeys())\n",
    "        classifiers=[]\n",
    "        weights=[]\n",
    "        for k in sorted_distances:\n",
    "            classifiers.append(k)\n",
    "            weights.append(distances[k])\n",
    "        normalized_weights = euclidean_norm_dict(weights)\n",
    "    normalized_weights_inverted=[0]*len(normalized_weights)\n",
    "    for i in range(len(normalized_weights)):\n",
    "        normalized_weights_inverted[i] = 1 - normalized_weights[i] \n",
    "            ####################\n",
    "    for i in range(len(classifiers)):\n",
    "        \n",
    "        if sframe[classifiers[i]+'_prediction']=='POS':\n",
    "            score+=normalized_weights_inverted[i]\n",
    "        elif sframe[classifiers[i]+'_prediction']=='NEG':\n",
    "            score+=0\n",
    "        if i>topk:\n",
    "            break\n",
    "    if score> sum(normalized_weights_inverted) * threshold:\n",
    "        return 'POS'\n",
    "    else:\n",
    "        return 'NEG'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.111936 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.111936 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\AlarmClockpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 898 lines in 0.165904 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 898 lines in 0.165904 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.120929 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.120929 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Babypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 912 lines in 0.516703 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 912 lines in 0.516703 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.135923 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.135923 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Bagpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.182895 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.182895 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.192889 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.192889 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\CableModempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 966 lines in 0.206881 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 966 lines in 0.206881 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.131923 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.131923 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Dumbbellpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 910 lines in 0.229868 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 910 lines in 0.229868 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.165906 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.165906 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Flashlightpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 924 lines in 0.21088 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 924 lines in 0.21088 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.112934 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.112934 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Glovespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 923 lines in 0.142921 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 923 lines in 0.142921 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.181895 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.181895 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GPSpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 918 lines in 0.223871 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 918 lines in 0.223871 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.189891 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.189891 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\GraphicsCardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 933 lines in 0.298826 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 933 lines in 0.298826 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.165904 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.165904 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Headphonepdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 891 lines in 0.24286 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 891 lines in 0.24286 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.216875 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.216875 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\HomeTheaterSystempdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 905 lines in 0.278839 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 905 lines in 0.278839 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.087947 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.087947 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Jewelrypdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 901 lines in 0.117932 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 901 lines in 0.117932 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.187891 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.187891 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Keyboardpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 896 lines in 0.227867 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 896 lines in 0.227867 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.127928 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.127928 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Magazine_Subscriptionspdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.151898 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.151898 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.139919 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.139919 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Movies_TVpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 930 lines in 0.213853 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 930 lines in 0.213853 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.200882 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.200882 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Projectorpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 919 lines in 0.244858 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 919 lines in 0.244858 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.14092 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.14092 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\RiceCookerpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 939 lines in 0.171901 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 939 lines in 0.171901 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.116934 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.116934 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Sandalpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 950 lines in 0.168902 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 950 lines in 0.168902 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.19289 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.19289 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Vacuumpdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 920 lines in 0.210878 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 920 lines in 0.210878 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.179896 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.179896 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,long,str,str,dict,dict,dict,dict,dict,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\Omar\\Video_Gamespdposneg_bl_wordnet.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 908 lines in 0.257841 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 908 lines in 0.257841 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ToolkitError",
     "evalue": "Runtime Exception: 110. Fail executing the lambda function. The lambda worker may have run out of memory or crashed because it captured objects that cannot be properly serialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mToolkitError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e53c041221d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aggregated_prediction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aggregated_prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mFscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'posneg_bl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aggregated_prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mFscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Fscore of the aggregation on the \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" domain\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Omar\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\toolkits\\evaluation.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(targets, predictions, average)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \"\"\"\n\u001b[1;32m--> 679\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Omar\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\toolkits\\evaluation.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(targets, predictions, beta, average)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \"average\" : average}\n\u001b[0;32m    560\u001b[0m     return _graphlab.extensions._supervised_streaming_evaluator(targets,\n\u001b[1;32m--> 561\u001b[1;33m                           predictions, \"fbeta_score\", opts)\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Omar\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\extensions.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_make_injected_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_run_toolkit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_class_instance_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Omar\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\graphlab\\extensions.pyc\u001b[0m in \u001b[0;36m_run_toolkit_function\u001b[1;34m(fnname, arguments, args, kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0m_ToolkitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0m_ToolkitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Toolkit failed with unknown error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mToolkitError\u001b[0m: Runtime Exception: 110. Fail executing the lambda function. The lambda worker may have run out of memory or crashed because it captured objects that cannot be properly serialized."
     ]
    }
   ],
   "source": [
    "##inverted distance -Unbalanced Cosine - No wordnet\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "for j in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "        negsamples=domains[d][domains[d]['Label']=='NEG']\n",
    "        possamples = domains[d][domains[d]['Label']=='POS']\n",
    "        negativedistr[d] = float(len(negsamples)) / float(len(possamples)) * 100\n",
    "        negsamplessize = float(len(possamples))  * negativedistr[d] / 100\n",
    "        newnegativesamplesizes[d] = int(negsamplessize)\n",
    "\n",
    "        domains[d+'posneg_bl'] = possamples\n",
    "        proportion= float(newnegativesamplesizes[d]) / float(len(negsamples))\n",
    "        initial=True\n",
    "        while initial:  \n",
    "            random_negsamples = negsamples.sample(proportion)\n",
    "            if len(random_negsamples)>= newnegativesamplesizes[d]:\n",
    "                reducednegativesamples = random_negsamples[:newnegativesamplesizes[d]]\n",
    "                initial=False\n",
    "        #domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(negsamples[:newnegativesamplesizes[d]])\n",
    "        domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(reducednegativesamples)\n",
    "        \n",
    "        #print \"Negative Samples\"\n",
    "        #print actualnegativedistr[d]\n",
    "        #print \"new negative sample sizes\"\n",
    "        #print newnegativesamplesizes[d]\n",
    "        #print \"Positive Samples\"\n",
    "        #print len(possamples)\n",
    "        #print len(domains[d+'posneg'])\n",
    "        #print len(domains[d+'posneg_bl'])\n",
    "        #print len(reducednegativesamples)\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    for d in domainnames:\n",
    "        counter+=1\n",
    "        print counter\n",
    "        #domains[d+'posneg_bl']['1-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 1)\n",
    "        #domains[d+'posneg_bl']['2-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 2)\n",
    "        #domains[d+'posneg_bl']['3-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 3)\n",
    "        #domains[d+'posneg_bl']['word_count'] = gl.text_analytics.count_words(domains[d+'posneg_bl']['Review'])\n",
    "        #domains[d+'posneg_bl']['tfidf'] = gl.text_analytics.tf_idf(domains[d+'posneg_bl']['word_count'])\n",
    "        domains[d+'posneg_bl'].save(d+'posneg_bl_wordnet.csv')\n",
    "    \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "        #0.5 then topk=21 cosine\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl'] = gl.SFrame(d+'posneg_bl_wordnet.csv')\n",
    "        for d in domainnames:\n",
    "            euc = True\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "        def flip(label):\n",
    "            if label=='NEG':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "            #domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            #domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "            print Acc\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print \"test set \"+str(j)+\" is processed\"\n",
    "    print Fscore_avgs\n",
    "    print Acc_avgs\n",
    "print Fscore_avgs\n",
    "print Acc_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##inverted distance Unbalanced Euc - No wordnet\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "for j in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "        negsamples=domains[d][domains[d]['Label']=='NEG']\n",
    "        possamples = domains[d][domains[d]['Label']=='POS']\n",
    "        negativedistr[d] = float(len(negsamples)) / float(len(possamples)) * 100\n",
    "        negsamplessize = float(len(possamples))  * negativedistr[d] / 100\n",
    "        newnegativesamplesizes[d] = int(negsamplessize)\n",
    "\n",
    "        domains[d+'posneg_bl'] = possamples\n",
    "        proportion= float(newnegativesamplesizes[d]) / float(len(negsamples))\n",
    "        initial=True\n",
    "        while initial:  \n",
    "            random_negsamples = negsamples.sample(proportion)\n",
    "            if len(random_negsamples)>= newnegativesamplesizes[d]:\n",
    "                reducednegativesamples = random_negsamples[:newnegativesamplesizes[d]]\n",
    "                initial=False\n",
    "        #domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(negsamples[:newnegativesamplesizes[d]])\n",
    "        domains[d+'posneg_bl'] = domains[d+'posneg_bl'].append(reducednegativesamples)\n",
    "        \n",
    "        #print \"Negative Samples\"\n",
    "        #print actualnegativedistr[d]\n",
    "        #print \"new negative sample sizes\"\n",
    "        #print newnegativesamplesizes[d]\n",
    "        #print \"Positive Samples\"\n",
    "        #print len(possamples)\n",
    "        #print len(domains[d+'posneg'])\n",
    "        #print len(domains[d+'posneg_bl'])\n",
    "        #print len(reducednegativesamples)\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    import graphlab\n",
    "    counter=0\n",
    "    for d in domainnames:\n",
    "        counter+=1\n",
    "        print counter\n",
    "        #domains[d+'posneg_bl']['1-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 1)\n",
    "        #domains[d+'posneg_bl']['2-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 2)\n",
    "        #domains[d+'posneg_bl']['3-grams'] = graphlab.text_analytics.count_ngrams(domains[d+'posneg_bl']['Review'], 3)\n",
    "        #domains[d+'posneg_bl']['word_count'] = gl.text_analytics.count_words(domains[d+'posneg_bl']['Review'])\n",
    "        #domains[d+'posneg_bl']['tfidf'] = gl.text_analytics.tf_idf(domains[d+'posneg_bl']['word_count'])\n",
    "        domains[d+'posneg_bl'].save(d+'posneg_bl_wordnet.csv')\n",
    "    \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "        #0.5 then topk=21 cosine\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl'] = gl.SFrame(d+'posneg_bl_wordnet.csv')\n",
    "        for d in domainnames:\n",
    "            euc = False\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "        def flip(label):\n",
    "            if label=='NEG':\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "\n",
    "            #domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            #domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "        for d in domainnames:\n",
    "            domains[d+'posneg_bl']['Label'] = domains[d+'posneg_bl']['Label'].apply(lambda x: flip(x))\n",
    "            domains[d+'posneg_bl']['aggregated_prediction'] = domains[d+'posneg_bl']['aggregated_prediction'].apply(lambda x: flip(x))\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_bl']['Label'], domains[d+'posneg_bl']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "            print Acc\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print \"test set \"+str(j)+\" is processed\"\n",
    "    print Fscore_avgs\n",
    "    print Acc_avgs\n",
    "print Fscore_avgs\n",
    "print Acc_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.8606618875947418]\n",
      "[0.8454999999999998]\n",
      "0.6\n",
      "Accuracies\n",
      "[0.8454999999999998]\n",
      "average accuracies across the five test sets:\n",
      "0.8455\n",
      "something is wrong with the average accuracy\n",
      "Fscores\n",
      "[0.8606618875947418]\n",
      "average fscores across the five test sets:\n",
      "0.860661887595\n",
      "something is wrong with the average fscore\n"
     ]
    }
   ],
   "source": [
    "##inverted distance   --balanced Euc - No Wordnet - LL\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "threshold_accs = defaultdict(list)\n",
    "threshold_fscores = defaultdict(list)\n",
    "for i in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "         for d in domainnames:\n",
    "        ##domains[d+'posneg'] = domains[d][domains[d]['Label']!='NEU']\n",
    "        #print domains[d+'posneg']\n",
    "        #newdomains.append(d+'posneg')\n",
    "            samples_pos = domains[d][domains[d]['Label']=='POS']\n",
    "            sample_pos_shuffled = gl.cross_validation.shuffle(samples_pos)\n",
    "            samples_neg = domains[d][domains[d]['Label']=='NEG']\n",
    "            sample_neg_shuffled = gl.cross_validation.shuffle(samples_neg)\n",
    "            domains[d+'pos'] = sample_pos_shuffled[:100] # domains[d][domains[d]['Label']=='POS'][:100]\n",
    "            domains[d+'neg'] = sample_neg_shuffled[:100] # domains[d][domains[d]['Label']=='NEG'][:100]\n",
    "        #print domains[d+'neg']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'pos']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'posneg_balanced'].append(domains[d+'neg'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    \n",
    "    for d in domainnames:\n",
    "        for j in domainnames:\n",
    "            if d!=j:\n",
    "                domains[d+'posneg_balanced'][j+'_prediction'] = domainclassifiers[j].predict(domains[d+'posneg_balanced'])\n",
    "    \n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "\n",
    "        for d in domainnames:\n",
    "            euc = True ## Euclidean\n",
    "            domains[d+'posneg_balanced']['aggregated_prediction'] = domains[d+'posneg_balanced'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        \n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "\n",
    "        for d in domainnames:\n",
    "\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            #print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            #print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            #print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        threshold_accs[thresh[i]].append(Acc_avg)\n",
    "        threshold_fscores[thresh[i]].append(Fscore_avg)\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "#print Fscore_avgs\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print counter\n",
    "print Fscore_avgs\n",
    "print Acc_avgs\n",
    "\n",
    "for i in range(len(thresh)):\n",
    "    print thresh[i]\n",
    "    print \"Accuracies\"\n",
    "    print threshold_accs[thresh[i]]\n",
    "    print \"average accuracies across the five test sets:\"\n",
    "    print sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]])\n",
    "    if sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]]) != sum(threshold_accs[thresh[i]]) / 5:\n",
    "        print \"something is wrong with the average accuracy\"\n",
    "    print \"Fscores\"\n",
    "    print threshold_fscores[thresh[i]]\n",
    "    print \"average fscores across the five test sets:\"\n",
    "    print sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]])\n",
    "    if sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]]) != sum(threshold_fscores[thresh[i]]) / 5:\n",
    "        print \"something is wrong with the average fscore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.8580244215811168]\n",
      "[0.8425]\n",
      "0.6\n",
      "Accuracies\n",
      "[0.8425]\n",
      "average accuracies across the five test sets:\n",
      "0.8425\n",
      "Fscores\n",
      "[0.8580244215811168]\n",
      "average fscores across the five test sets:\n",
      "0.858024421581\n"
     ]
    }
   ],
   "source": [
    "##inverted distance --balanced Cosine - No Wordnet - LL\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "threshold_accs = defaultdict(list)\n",
    "threshold_fscores = defaultdict(list)\n",
    "for i in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "         for d in domainnames:\n",
    "        ##domains[d+'posneg'] = domains[d][domains[d]['Label']!='NEU']\n",
    "        #print domains[d+'posneg']\n",
    "        #newdomains.append(d+'posneg')\n",
    "            samples_pos = domains[d][domains[d]['Label']=='POS']\n",
    "            sample_pos_shuffled = gl.cross_validation.shuffle(samples_pos)\n",
    "            samples_neg = domains[d][domains[d]['Label']=='NEG']\n",
    "            sample_neg_shuffled = gl.cross_validation.shuffle(samples_neg)\n",
    "            domains[d+'pos'] = sample_pos_shuffled[:100] # domains[d][domains[d]['Label']=='POS'][:100]\n",
    "            domains[d+'neg'] = sample_neg_shuffled[:100] # domains[d][domains[d]['Label']=='NEG'][:100]\n",
    "            #print domains[d+'neg']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'pos']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'posneg_balanced'].append(domains[d+'neg'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    \n",
    "    for d in domainnames:\n",
    "        for j in domainnames:\n",
    "            if d!=j:\n",
    "                domains[d+'posneg_balanced'][j+'_prediction'] = domainclassifiers[j].predict(domains[d+'posneg_balanced'])\n",
    "    \n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.6]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "\n",
    "        for d in domainnames:\n",
    "            euc = False ## Euclidean\n",
    "            domains[d+'posneg_balanced']['aggregated_prediction'] = domains[d+'posneg_balanced'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        \n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "\n",
    "        for d in domainnames:\n",
    "\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            #print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            #print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            #print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        threshold_accs[thresh[i]].append(Acc_avg)\n",
    "        threshold_fscores[thresh[i]].append(Fscore_avg)\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "#print Fscore_avgs\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print counter\n",
    "print Fscore_avgs\n",
    "print Acc_avgs\n",
    "\n",
    "for i in range(len(thresh)):\n",
    "    print thresh[i]\n",
    "    print \"Accuracies\"\n",
    "    print threshold_accs[thresh[i]]\n",
    "    print \"average accuracies across the five test sets:\"\n",
    "    print sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]])\n",
    "    if sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]]) != sum(threshold_accs[thresh[i]]) / 1:\n",
    "        print \"something is wrong with the average accuracy\"\n",
    "    print \"Fscores\"\n",
    "    print threshold_fscores[thresh[i]]\n",
    "    print \"average fscores across the five test sets:\"\n",
    "    print sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]])\n",
    "    if sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]]) != sum(threshold_fscores[thresh[i]]) / 1:\n",
    "        print \"something is wrong with the average fscore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.8666002865590714]\n",
      "[0.8665]\n",
      "0.7\n",
      "Accuracies\n",
      "[0.8665]\n",
      "average accuracies across the five test sets:\n",
      "0.8665\n",
      "something is wrong with the average accuracy\n",
      "Fscores\n",
      "[0.8666002865590714]\n",
      "average fscores across the five test sets:\n",
      "0.866600286559\n",
      "something is wrong with the average fscore\n"
     ]
    }
   ],
   "source": [
    "##inverted distance   --balanced Euc - No Wordnet - LL th=0.7\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "threshold_accs = defaultdict(list)\n",
    "threshold_fscores = defaultdict(list)\n",
    "for i in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "         for d in domainnames:\n",
    "        ##domains[d+'posneg'] = domains[d][domains[d]['Label']!='NEU']\n",
    "        #print domains[d+'posneg']\n",
    "        #newdomains.append(d+'posneg')\n",
    "            samples_pos = domains[d][domains[d]['Label']=='POS']\n",
    "            sample_pos_shuffled = gl.cross_validation.shuffle(samples_pos)\n",
    "            samples_neg = domains[d][domains[d]['Label']=='NEG']\n",
    "            sample_neg_shuffled = gl.cross_validation.shuffle(samples_neg)\n",
    "            domains[d+'pos'] = sample_pos_shuffled[:100] # domains[d][domains[d]['Label']=='POS'][:100]\n",
    "            domains[d+'neg'] = sample_neg_shuffled[:100] # domains[d][domains[d]['Label']=='NEG'][:100]\n",
    "        #print domains[d+'neg']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'pos']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'posneg_balanced'].append(domains[d+'neg'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    \n",
    "    for d in domainnames:\n",
    "        for j in domainnames:\n",
    "            if d!=j:\n",
    "                domains[d+'posneg_balanced'][j+'_prediction'] = domainclassifiers[j].predict(domains[d+'posneg_balanced'])\n",
    "    \n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.7]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "\n",
    "        for d in domainnames:\n",
    "            euc = True ## Euclidean\n",
    "            domains[d+'posneg_balanced']['aggregated_prediction'] = domains[d+'posneg_balanced'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        \n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "\n",
    "        for d in domainnames:\n",
    "\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            #print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            #print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            #print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        threshold_accs[thresh[i]].append(Acc_avg)\n",
    "        threshold_fscores[thresh[i]].append(Fscore_avg)\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "#print Fscore_avgs\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print counter\n",
    "print Fscore_avgs\n",
    "print Acc_avgs\n",
    "\n",
    "for i in range(len(thresh)):\n",
    "    print thresh[i]\n",
    "    print \"Accuracies\"\n",
    "    print threshold_accs[thresh[i]]\n",
    "    print \"average accuracies across the five test sets:\"\n",
    "    print sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]])\n",
    "    if sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]]) != sum(threshold_accs[thresh[i]]) / 5:\n",
    "        print \"something is wrong with the average accuracy\"\n",
    "    print \"Fscores\"\n",
    "    print threshold_fscores[thresh[i]]\n",
    "    print \"average fscores across the five test sets:\"\n",
    "    print sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]])\n",
    "    if sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]]) != sum(threshold_fscores[thresh[i]]) / 5:\n",
    "        print \"something is wrong with the average fscore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.8648113328425314]\n",
      "[0.8644999999999999]\n",
      "0.7\n",
      "Accuracies\n",
      "[0.8644999999999999]\n",
      "average accuracies across the five test sets:\n",
      "0.8645\n",
      "Fscores\n",
      "[0.8648113328425314]\n",
      "average fscores across the five test sets:\n",
      "0.864811332843\n"
     ]
    }
   ],
   "source": [
    "##inverted distance --balanced Cosine - No Wordnet - LL\n",
    "from collections import defaultdict\n",
    "Fscore_avgs = []\n",
    "Acc_avgs = []\n",
    "threshold_accs = defaultdict(list)\n",
    "threshold_fscores = defaultdict(list)\n",
    "for i in range(1):\n",
    "    domainnames = ['AlarmClockpd' ,'Babypd','Bagpd', 'CableModempd', 'Dumbbellpd', 'Flashlightpd', 'Glovespd', 'GPSpd', 'GraphicsCardpd', 'Headphonepd'\n",
    "        ,'HomeTheaterSystempd', 'Jewelrypd', 'Keyboardpd', 'Magazine_Subscriptionspd', 'Movies_TVpd', 'Projectorpd', 'RiceCookerpd', 'Sandalpd',\n",
    "        'Vacuumpd','Video_Gamespd']\n",
    "\n",
    "    #actualnegativedistr={}\n",
    "    newnegativesamplesizes={}\n",
    "    euclidean_distances = defaultdict(dict)\n",
    "    distances = {}\n",
    "    cosine_distances = defaultdict(dict)\n",
    "    for d in domainnames:\n",
    "\n",
    "        #print \"New number of negative samples in \"+d+\":\"\n",
    "         for d in domainnames:\n",
    "        ##domains[d+'posneg'] = domains[d][domains[d]['Label']!='NEU']\n",
    "        #print domains[d+'posneg']\n",
    "        #newdomains.append(d+'posneg')\n",
    "            samples_pos = domains[d][domains[d]['Label']=='POS']\n",
    "            sample_pos_shuffled = gl.cross_validation.shuffle(samples_pos)\n",
    "            samples_neg = domains[d][domains[d]['Label']=='NEG']\n",
    "            sample_neg_shuffled = gl.cross_validation.shuffle(samples_neg)\n",
    "            domains[d+'pos'] = sample_pos_shuffled[:100] # domains[d][domains[d]['Label']=='POS'][:100]\n",
    "            domains[d+'neg'] = sample_neg_shuffled[:100] # domains[d][domains[d]['Label']=='NEG'][:100]\n",
    "            #print domains[d+'neg']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'pos']\n",
    "            domains[d+'posneg_balanced'] = domains[d+'posneg_balanced'].append(domains[d+'neg'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import graphlab\n",
    "    \n",
    "    for d in domainnames:\n",
    "        for j in domainnames:\n",
    "            if d!=j:\n",
    "                domains[d+'posneg_balanced'][j+'_prediction'] = domainclassifiers[j].predict(domains[d+'posneg_balanced'])\n",
    "    \n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "\n",
    "\n",
    "            \n",
    "    thresh = [0.7]\n",
    "    domain_Fscore=[]\n",
    "    domain_acc = []\n",
    "    topk=21\n",
    "    for i in range(len(thresh)): \n",
    "    \n",
    "\n",
    "        for d in domainnames:\n",
    "            euc = False ## Euclidean\n",
    "            domains[d+'posneg_balanced']['aggregated_prediction'] = domains[d+'posneg_balanced'].apply(lambda x: classify_lifelong_inverted_distance(x,d,thresh[i],topk,euc))\n",
    "\n",
    "\n",
    "        \n",
    "        Fscores =[]\n",
    "        Accs=[]\n",
    "\n",
    "        for d in domainnames:\n",
    "\n",
    "            Fscore = graphlab.evaluation.f1_score(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'],average = None)\n",
    "            Fscores.append(Fscore)\n",
    "            #print \"Fscore of the aggregation on the \"+d+\" domain\"\n",
    "            #print Fscore\n",
    "            Acc = graphlab.evaluation.accuracy(domains[d+'posneg_balanced']['Label'], domains[d+'posneg_balanced']['aggregated_prediction'])\n",
    "            Accs.append(Acc)\n",
    "            #print \"Accuracy of the aggregation on the \"+d+\" domain\"\n",
    "\n",
    "        Fscore_avg = sum(Fscores) / len(Fscores)\n",
    "        #print \" The average Fscore on the unbalanced data set is\"\n",
    "        #print Fscore_avg\n",
    "        Acc_avg = sum(Accs) / len(Accs)\n",
    "        #print \" The average Accuracy on the unbalanced data set is\"\n",
    "        #print Acc_avg\n",
    "        threshold_accs[thresh[i]].append(Acc_avg)\n",
    "        threshold_fscores[thresh[i]].append(Fscore_avg)\n",
    "        domain_Fscore.append(Fscore_avg)\n",
    "        domain_acc.append(Acc_avg)\n",
    "#print Fscore_avgs\n",
    "    Fscore_avgs.append(max(domain_Fscore))\n",
    "    Acc_avgs.append(max(domain_acc))\n",
    "    print counter\n",
    "print Fscore_avgs\n",
    "print Acc_avgs\n",
    "\n",
    "for i in range(len(thresh)):\n",
    "    print thresh[i]\n",
    "    print \"Accuracies\"\n",
    "    print threshold_accs[thresh[i]]\n",
    "    print \"average accuracies across the five test sets:\"\n",
    "    print sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]])\n",
    "    if sum(threshold_accs[thresh[i]]) / len(threshold_accs[thresh[i]]) != sum(threshold_accs[thresh[i]]) / 1:\n",
    "        print \"something is wrong with the average accuracy\"\n",
    "    print \"Fscores\"\n",
    "    print threshold_fscores[thresh[i]]\n",
    "    print \"average fscores across the five test sets:\"\n",
    "    print sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]])\n",
    "    if sum(threshold_fscores[thresh[i]]) / len(threshold_fscores[thresh[i]]) != sum(threshold_fscores[thresh[i]]) / 1:\n",
    "        print \"something is wrong with the average fscore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
